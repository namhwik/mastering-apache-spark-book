== Debugging Query Execution

`debug` package object contains tools for *debugging query execution* that you can use to do the full analysis of your link:spark-sql-Dataset.adoc[structured queries] (i.e. `Datasets`).

NOTE: Let's make it clear -- they are methods, _my dear_.

The methods are in `org.apache.spark.sql.execution.debug` package and work on your `Datasets` and link:spark-sql-SparkSession.adoc[SparkSession].

CAUTION: FIXME Expand on the `SparkSession` part.

[source, scala]
----
debug()
debugCodegen()
----

Import the package and do the full analysis using <<debug, debug>> or <<debugCodegen, debugCodegen>> methods.

=== [[debug]] `debug` Method

[source, scala]
----
import org.apache.spark.sql.execution.debug._

scala> spark.range(10).where('id === 4).debug
Results returned: 1
== WholeStageCodegen ==
Tuples output: 1
 id LongType: {java.lang.Long}
== Filter (id#25L = 4) ==
Tuples output: 0
 id LongType: {}
== Range (0, 10, splits=8) ==
Tuples output: 0
 id LongType: {}
----

=== [[debugCodegen]] "Debugging" Codegen -- `debugCodegen` Method

You use `debugCodegen` method to review the link:spark-sql-CodegenSupport.adoc[CodegenSupport]-generated code.

[source, scala]
----
import org.apache.spark.sql.execution.debug._

scala> spark.range(10).where('id === 4).debugCodegen
Found 1 WholeStageCodegen subtrees.
== Subtree 1 / 1 ==
*Filter (id#29L = 4)
+- *Range (0, 10, splits=8)

Generated code:
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
/* 006 */   private Object[] references;
...
----

[NOTE]
====
`debugCodegen` is equivalent to using `debug` interface of the link:spark-sql-Dataset.adoc#queryExecution[QueryExecution].

[source, scala]
----
val q = spark.range(1, 1000).select('id+1+2+3, 'id+4+5+6)
scala> q.queryExecution.debug.codegen
Found 1 WholeStageCodegen subtrees.
== Subtree 1 / 1 ==
*Project [(id#3L + 6) AS (((id + 1) + 2) + 3)#6L, (id#3L + 15) AS (((id + 4) + 5) + 6)#7L]
+- *Range (1, 1000, step=1, splits=8)

Generated code:
/* 001 */ public Object generate(Object[] references) {
/* 002 */   return new GeneratedIterator(references);
/* 003 */ }
/* 004 */
/* 005 */ final class GeneratedIterator extends org.apache.spark.sql.execution.BufferedRowIterator {
...
----
====
