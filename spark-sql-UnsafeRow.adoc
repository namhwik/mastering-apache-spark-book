== [[UnsafeRow]] UnsafeRow -- Mutable Raw-Memory Unsafe Binary Row Format

`UnsafeRow` is a concrete link:spark-sql-InternalRow.adoc[InternalRow] that represents a mutable internal raw-memory (and hence unsafe) binary row format.

In other words, `UnsafeRow` is an `InternalRow` that is backed by raw memory instead of Java objects.

[source, scala]
----
// Use ExpressionEncoder for simplicity
import org.apache.spark.sql.catalyst.encoders.ExpressionEncoder
val stringEncoder = ExpressionEncoder[String]
val row = stringEncoder.toRow("hello world")

import org.apache.spark.sql.catalyst.expressions.UnsafeRow
val unsafeRow = row match { case ur: UnsafeRow => ur }

scala> println(unsafeRow.getSizeInBytes)
32

scala> unsafeRow.getBytes
res0: Array[Byte] = Array(0, 0, 0, 0, 0, 0, 0, 0, 11, 0, 0, 0, 16, 0, 0, 0, 104, 101, 108, 108, 111, 32, 119, 111, 114, 108, 100, 0, 0, 0, 0, 0)

scala> unsafeRow.getUTF8String(0)
res1: org.apache.spark.unsafe.types.UTF8String = hello world
----

`UnsafeRow` supports Java's <<Externalizable, Externalizable>> and Kryo's <<KryoSerializable, KryoSerializable>> serialization/deserialization protocols.

The fields of a data row are placed using *field offsets*.

[[mutableFieldTypes]]
[[mutable-types]]
UnsafeRow's mutable field link:spark-sql-DataType.adoc[data types] (in alphabetical order):

* `BooleanType`
* `ByteType`
* `DateType`
* `DoubleType`
* `FloatType`
* `IntegerType`
* `LongType`
* `NullType`
* `ShortType`
* `TimestampType`

`UnsafeRow` is composed of three regions:

1. Null Bit Set Bitmap Region (1 bit/field) for tracking null values
1. Fixed-Length 8-Byte Values Region
1. Variable-Length Data Section

That gives the property of rows being always 8-byte word aligned and so their size is always a multiple of 8 bytes.

Equality comparision and hashing of rows can be performed on raw bytes since if two rows are identical so should be their bit-wise representation. No type-specific interpretation is required.

=== [[isMutable]] `isMutable` Method

[source, java]
----
static boolean isMutable(DataType dt)
----

`isMutable` is enabled (i.e. returns `true`) when the input `dt` link:spark-sql-DataType.adoc[DataType] is a <<mutableFieldTypes, mutable field type>> or link:spark-sql-DataType.adoc#DecimalType[DecimalType].

Otherwise, `isMutable` is disabled (i.e. returns `false`).

[NOTE]
====
`isMutable` is used when:

* `UnsafeFixedWidthAggregationMap` does `supportsAggregationBufferSchema`
* `SortBasedAggregationIterator` does `newBuffer`
====

=== [[KryoSerializable]] Kryo's KryoSerializable SerDe Protocol

TIP: Read up on https://github.com/EsotericSoftware/kryo#kryoserializable[KryoSerializable].

==== [[write]] Serializing JVM Object -- KryoSerializable's `write` Method

[source, java]
----
void write(Kryo kryo, Output out)
----

==== [[read]] Deserializing Kryo-Managed Object -- KryoSerializable's `read` Method

[source, java]
----
void read(Kryo kryo, Input in)
----

=== [[Externalizable]] Java's Externalizable SerDe Protocol

TIP: Read up on https://docs.oracle.com/javase/8/docs/api/java/io/Externalizable.html[java.io.Externalizable].

==== [[writeExternal]] Serializing JVM Object -- Externalizable's `writeExternal` Method

[source, java]
----
void writeExternal(ObjectOutput out)
throws IOException
----

==== [[readExternal]] Deserializing Java-Externalized Object -- Externalizable's `readExternal` Method

[source, java]
----
void readExternal(ObjectInput in)
throws IOException, ClassNotFoundException
----
