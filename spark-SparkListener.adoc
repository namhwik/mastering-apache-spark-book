== [[SparkListener]] Spark Listeners -- Intercepting Events from Spark Scheduler

A `SparkListener` intercepts events from the Spark scheduler that it emits over the course of execution of a Spark application.

A Spark listener is an implementation of the `SparkListener` developer API that is an extension of <<SparkListenerInterface, SparkListenerInterface>> where all the _callback methods_ are no-op/do-nothing.

Spark uses Spark listeners for link:spark-webui.adoc[web UI], link:spark-scheduler-listeners-eventlogginglistener.adoc[event persistence] (for History Server), link:spark-service-executor-allocation-manager.adoc[dynamic allocation of executors] and <<builtin-implementations, other services>>.

You can develop your own custom Spark listener using the `SparkListener` developer API and register it using link:spark-sparkcontext.adoc#addSparkListener[SparkContext.addSparkListener] method or link:spark-LiveListenerBus.adoc#spark_extraListeners[spark.extraListeners] setting. With `SparkListener` you can focus on Spark events of your liking and process a subset of scheduling events.

TIP: Developing a custom SparkListener is an excellent introduction to low-level details of link:spark-execution-model.adoc[Spark's Execution Model]. Check out the exercise link:exercises/spark-exercise-custom-scheduler-listener.adoc[Developing Custom SparkListener to monitor DAGScheduler in Scala].

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.SparkContext` logger to see when custom Spark listeners are registered.

```
INFO SparkContext: Registered listener org.apache.spark.scheduler.StatsReportListener
```

See link:spark-sparkcontext.adoc[`SparkContext` -- Entry Point to Spark (Core)].
====

=== [[SparkListenerInterface]] `SparkListenerInterface` -- Internal Contract for Spark Listeners

`SparkListenerInterface` is an `private[spark]` contract for Spark listeners to intercept events from the Spark scheduler.

NOTE: <<SparkListener, SparkListener>> and <<SparkFirehoseListener, SparkFirehoseListener>> Spark listeners are direct implementations of `SparkListenerInterface` contract to help developing more sophisticated Spark listeners.

.`SparkListenerInterface` Methods (listed in alphabetical order)
[frame="topbot",cols="1,1,2",options="header",width="100%"]
|======================
| Method | Event | Reason
| `onApplicationEnd` | [[SparkListenerApplicationEnd]] `SparkListenerApplicationEnd` |
`SparkContext` does `postApplicationEnd`.

| `onApplicationStart` | [[SparkListenerApplicationStart]] `SparkListenerApplicationStart` |
`SparkContext` does `postApplicationStart`.

| `onBlockManagerAdded` | [[SparkListenerBlockManagerAdded]] `SparkListenerBlockManagerAdded` |
link:spark-blockmanager-BlockManagerMasterEndpoint.adoc#register[`BlockManagerMasterEndpoint` has registered a `BlockManager`].

| `onBlockManagerRemoved` | [[SparkListenerBlockManagerRemoved]] `SparkListenerBlockManagerRemoved` |
link:spark-blockmanager-BlockManagerMasterEndpoint.adoc#removeBlockManager[`BlockManagerMasterEndpoint` has removed a `BlockManager`].

| `onBlockUpdated` | [[SparkListenerBlockUpdated]] `SparkListenerBlockUpdated` |
link:spark-blockmanager-BlockManagerMasterEndpoint.adoc[`BlockManagerMasterEndpoint` has received a `UpdateBlockInfo` message].

| `onEnvironmentUpdate` | [[SparkListenerEnvironmentUpdate]] `SparkListenerEnvironmentUpdate` |
`SparkContext` does `postEnvironmentUpdate`.

| `onExecutorMetricsUpdate` | [[SparkListenerExecutorMetricsUpdate]] `SparkListenerExecutorMetricsUpdate` |

| `onExecutorAdded` | [[SparkListenerExecutorAdded]] `SparkListenerExecutorAdded` |
link:spark-scheduler-backends-CoarseGrainedSchedulerBackend.adoc#RegisterExecutor[`DriverEndpoint` RPC endpoint (of `CoarseGrainedSchedulerBackend`) handles `RegisterExecutor` message], `MesosFineGrainedSchedulerBackend` does `resourceOffers`, and `LocalSchedulerBackendEndpoint` starts.

| `onExecutorRemoved` | [[SparkListenerExecutorRemoved]] `SparkListenerExecutorRemoved` |
link:spark-scheduler-backends-CoarseGrainedSchedulerBackend.adoc#removeExecutor[`DriverEndpoint` RPC endpoint (of `CoarseGrainedSchedulerBackend`) does `removeExecutor`] and `MesosFineGrainedSchedulerBackend` does `removeExecutor`.

| `onJobEnd` | [[SparkListenerJobEnd]] `SparkListenerJobEnd` |
`DAGScheduler` does `cleanUpAfterSchedulerStop`, `handleTaskCompletion`, `failJobAndIndependentStages`, and markMapStageJobAsFinished.

| `onJobStart` | [[SparkListenerJobStart]] `SparkListenerJobStart` |
`DAGScheduler` does `handleJobSubmitted` and `handleMapStageSubmitted`.

| `onStageCompleted` | [[SparkListenerStageCompleted]] `SparkListenerStageCompleted` |
`DAGScheduler` does `markStageAsFinished`.

| `onStageSubmitted` | [[SparkListenerStageSubmitted]] `SparkListenerStageSubmitted` |
`DAGScheduler` does `submitMissingTasks`.

| `onTaskEnd` | [[SparkListenerTaskEnd]] `SparkListenerTaskEnd` |
link:spark-dagscheduler.adoc#handleTaskCompletion[`DAGScheduler` handles a task completion].

| `onTaskGettingResult` | [[SparkListenerTaskGettingResult]] `SparkListenerTaskGettingResult` |
link:spark-dagscheduler-DAGSchedulerEventProcessLoop.adoc#handleGetTaskResult[`DAGScheduler` handles `GettingResultEvent` event].

| `onTaskStart` | [[SparkListenerTaskStart]] `SparkListenerTaskStart` |
`DAGScheduler` is informed that a link:spark-dagscheduler-DAGSchedulerEventProcessLoop.adoc#handleBeginEvent[task is being started].

| `onUnpersistRDD` | [[SparkListenerUnpersistRDD]] `SparkListenerUnpersistRDD` |
`SparkContext` does `unpersistRDD`.

| `onOtherEvent` | [[SparkListenerEvent]] `SparkListenerEvent` |
|======================

=== [[builtin-implementations]] Built-In Spark Listeners

.Built-In Spark Listeners
[frame="topbot",cols="1,2",options="header",width="100%"]
|======================
| Spark Listener | Description
| link:spark-scheduler-listeners-eventlogginglistener.adoc[EventLoggingListener] | Logs JSON-encoded events to a file that can later be read by link:spark-history-server.adoc[History Server]
| link:spark-scheduler-listeners-statsreportlistener.adoc[StatsReportListener] |
| [[SparkFirehoseListener]] `SparkFirehoseListener` | Allows users to receive all <<SparkListenerEvent, SparkListenerEvent>> events by overriding the single `onEvent` method only.
| link:spark-service-ExecutorAllocationListener.adoc[ExecutorAllocationListener] |
| link:spark-sparkcontext-HeartbeatReceiver.adoc[HeartbeatReceiver] |
| link:spark-streaming/spark-streaming-streaminglisteners.adoc#StreamingJobProgressListener[StreamingJobProgressListener] |
| link:spark-webui-executors-ExecutorsListener.adoc[ExecutorsListener] | Prepares information for link:spark-webui-executors.adoc[Executors tab] in link:spark-webui.adoc[web UI]
| link:spark-webui-StorageStatusListener.adoc[StorageStatusListener], link:spark-webui-RDDOperationGraphListener.adoc[RDDOperationGraphListener], link:spark-webui-EnvironmentListener.adoc[EnvironmentListener], link:spark-webui-BlockStatusListener.adoc[BlockStatusListener] and link:spark-webui-StorageListener.adoc[StorageListener] | For link:spark-webui.adoc[web UI]
| `SpillListener` |
| `ApplicationEventListener` |
| link:spark-sql-streaming-StreamingQueryListenerBus.adoc[StreamingQueryListenerBus] |
| link:spark-webui-SQLListener.adoc[SQLListener] / link:spark-history-server-SQLHistoryListener.adoc[SQLHistoryListener] | Support for link:spark-history-server.adoc[History Server]
| link:spark-streaming/spark-streaming-jobscheduler.adoc#StreamingListenerBus[StreamingListenerBus] |
| link:spark-webui-JobProgressListener.adoc[JobProgressListener] |
|======================
