== [[CoarseGrainedSchedulerBackend]] CoarseGrainedSchedulerBackend

`CoarseGrainedSchedulerBackend` is a link:spark-scheduler-backends.adoc[SchedulerBackend] and link:spark-service-ExecutorAllocationClient.adoc[ExecutorAllocationClient].

It is responsible for requesting resources from a cluster manager for executors to be able to <<launching-tasks, launch tasks>> (on link:spark-executor-backends-CoarseGrainedExecutorBackend.adoc[coarse-grained executors]).

This backend holds executors for the duration of the Spark job rather than relinquishing executors whenever a task is done and asking the scheduler to launch a new executor for each new task.

When <<creating-instance, being created>>, `CoarseGrainedSchedulerBackend` requires a link:spark-taskschedulerimpl.adoc[Task Scheduler], and a link:spark-rpc.adoc[RPC Environment].

It uses link:spark-LiveListenerBus.adoc[LiveListenerBus].

It registers <<CoarseGrainedScheduler, CoarseGrainedScheduler RPC Endpoint>> that executors use for RPC communication.

It tracks:

* the total number of cores in the cluster (using `totalCoreCount`)
* the total number of executors that are currently registered
* executors (`ExecutorData`)
* executors to be removed (`executorsPendingToRemove`)
* hosts and the number of possible tasks possibly running on them
* lost executors with no real exit reason
* tasks per slaves (`taskIdsOnSlave`)

Known Implementations:

1. Spark Standalone's link:spark-standalone-StandaloneSchedulerBackend.adoc[StandaloneSchedulerBackend]
2. Spark on YARN's link:yarn/spark-yarn-yarnschedulerbackend.adoc[YarnSchedulerBackend]
3. Spark on Mesos's link:spark-mesos/spark-mesos-MesosCoarseGrainedSchedulerBackend.adoc[MesosCoarseGrainedSchedulerBackend]

[TIP]
====
Enable `INFO` or `DEBUG` logging level for `org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.scheduler.cluster.CoarseGrainedSchedulerBackend=DEBUG
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[creating-instance]] Creating `CoarseGrainedSchedulerBackend` Instance

`CoarseGrainedSchedulerBackend` requires a link:spark-taskschedulerimpl.adoc[task scheduler] and a link:spark-rpc.adoc[RPC Environment] when being created.

It initializes the following registries:

* totalCoreCount to `0`
* totalRegisteredExecutors to `0`
* maxRpcMessageSize to <<spark_rpc_message_maxSize, spark.rpc.message.maxSize>>.
* _minRegisteredRatio to <<spark.scheduler.minRegisteredResourcesRatio, spark.scheduler.minRegisteredResourcesRatio>> (between `0` and `1` inclusive).
* maxRegisteredWaitingTimeMs to <<spark.scheduler.maxRegisteredResourcesWaitingTime, spark.scheduler.maxRegisteredResourcesWaitingTime>>.
* createTime to the current time.
* <<executorDataMap, executorDataMap>> to an empty collection.
* <<numPendingExecutors, numPendingExecutors>> to `0`
* <<executorsPendingToRemove, executorsPendingToRemove>> to an empty collection.
* <<hostToLocalTaskCount, hostToLocalTaskCount>> to an empty collection.
* <<localityAwareTasks, localityAwareTasks>> to `0`
* <<currentExecutorIdCounter, currentExecutorIdCounter>> to `0`

It accesses the current link:spark-LiveListenerBus.adoc[LiveListenerBus] and link:spark-configuration.adoc[SparkConf] through the constructor's reference to link:spark-taskschedulerimpl.adoc[TaskSchedulerImpl].

=== [[getExecutorIds]] Getting Executor Ids -- `getExecutorIds` Method

When called, `getExecutorIds` simply returns executor ids from the internal <<executorDataMap, executorDataMap>> registry.

NOTE: It is called when link:spark-sparkcontext.adoc#getExecutorIds[SparkContext calculates executor ids].

=== [[contract]] CoarseGrainedSchedulerBackend Contract

CAUTION: FIXME

* It can <<reset, reset a current internal state to the initial state>>.

==== [[doRequestTotalExecutors]] `doRequestTotalExecutors` Method

[source, scala]
----
doRequestTotalExecutors(requestedTotal: Int): Boolean = false
----

`doRequestTotalExecutors` requests `requestedTotal` executors from a cluster manager. It is a `protected` method that returns `false` by default (that coarse-grained scheduler backends are supposed to further customize).

[NOTE]
====
It is called when `CoarseGrainedSchedulerBackend` requests <<requestExecutors, additional>> or <<requestTotalExecutors, total number of executors>>, or when <<killExecutors, killing unneeded executors>>.

In fact, all the aforementioned methods are due to the link:spark-service-ExecutorAllocationClient.adoc[ExecutorAllocationClient contract] that `CoarseGrainedSchedulerBackend` follows.
====

NOTE: It is customized by the coarse-grained scheduler backends for  link:yarn/spark-yarn-yarnschedulerbackend.adoc#doRequestTotalExecutors[YARN], link:spark-standalone-StandaloneSchedulerBackend.adoc[Spark Standalone], and link:spark-mesos/spark-mesos-MesosCoarseGrainedSchedulerBackend.adoc[Mesos].

=== [[internal-registries]] Internal Registries

==== [[currentExecutorIdCounter]] `currentExecutorIdCounter` Counter

`currentExecutorIdCounter` is the last (highest) identifier of all <<RegisterExecutor, allocated executors>>.

NOTE: It is exclusively used in link:yarn/spark-yarn-cluster-YarnSchedulerEndpoint.adoc#RetrieveLastAllocatedExecutorId[`YarnSchedulerEndpoint` to respond to `RetrieveLastAllocatedExecutorId` message].

==== [[executorDataMap]] `executorDataMap` Registry

[source, scala]
----
executorDataMap = new HashMap[String, ExecutorData]
----

`executorDataMap` tracks executor data by executor id.

It uses `ExecutorData` that holds an executor's endpoint reference, address, host, the number of free and total CPU cores, the URL of execution logs.

NOTE: A new executor (id, data) pair is added when <<RegisterExecutor, `DriverEndpoint` receives `RegisterExecutor` message>> and removed when <<RemoveExecutor, `DriverEndpoint` receives `RemoveExecutor` message>> or <<DriverEndpoint-onDisconnected, a remote host (with one or many executors) disconnects>>.

==== [[numPendingExecutors]] `numPendingExecutors`

CAUTION: FIXME

==== [[numExistingExecutors]] `numExistingExecutors`

CAUTION: FIXME

==== [[executorsPendingToRemove]] `executorsPendingToRemove`

CAUTION: FIXME

==== [[localityAwareTasks]] `localityAwareTasks`

CAUTION: FIXME

==== [[hostToLocalTaskCount]] `hostToLocalTaskCount`

CAUTION: FIXME

=== [[requestExecutors]] Requesting Additional Executors -- `requestExecutors` Method

[source, scala]
----
requestExecutors(numAdditionalExecutors: Int): Boolean
----

`requestExecutors` is a "decorator" method that ultimately calls a cluster-specific <<doRequestTotalExecutors, doRequestTotalExecutors>> method and returns whether the request was acknowledged or not (it is assumed `false` by default).

NOTE: `requestExecutors` method is a part of link:spark-service-ExecutorAllocationClient.adoc[ExecutorAllocationClient Contract] that link:spark-sparkcontext.adoc#requestExecutors[SparkContext uses for requesting additional executors] (as a part of a developer API for dynamic allocation of executors).

When called, you should see the following INFO message followed by DEBUG message in the logs:

```
INFO Requesting [numAdditionalExecutors] additional executor(s) from the cluster manager
DEBUG Number of pending executors is now [numPendingExecutors]
```

The internal `numPendingExecutors` is increased by the input `numAdditionalExecutors`.

`requestExecutors` <<doRequestTotalExecutors, requests executors from a cluster manager>> (that reflects the current computation needs). The "new executor total" is a sum of the internal <<numExistingExecutors, numExistingExecutors>> and <<numPendingExecutors, numPendingExecutors>> decreased by the <<executorsPendingToRemove, number of executors pending to be removed>>.

If `numAdditionalExecutors` is negative, a `IllegalArgumentException` is thrown:

```
Attempted to request a negative number of additional executor(s) [numAdditionalExecutors] from the cluster manager. Please specify a positive number!
```

NOTE: It is a final method that no other scheduler backends could customize further.

NOTE: The method is a synchronized block that makes multiple concurrent requests be handled in a serial fashion, i.e. one by one.

=== [[requestTotalExecutors]] Requesting Exact Number of Executors -- `requestTotalExecutors` Method

[source, scala]
----
requestTotalExecutors(
  numExecutors: Int,
  localityAwareTasks: Int,
  hostToLocalTaskCount: Map[String, Int]): Boolean
----

`requestTotalExecutors` is a "decorator" method that ultimately calls a cluster-specific <<doRequestTotalExecutors, doRequestTotalExecutors>> method and returns whether the request was acknowledged or not (it is assumed `false` by default).

NOTE: `requestTotalExecutors` is a part of link:spark-service-ExecutorAllocationClient.adoc[ExecutorAllocationClient Contract] that link:spark-sparkcontext.adoc#requestTotalExecutors[SparkContext uses for requesting the exact number of executors].

It sets the internal <<localityAwareTasks, localityAwareTasks>> and <<hostToLocalTaskCount, hostToLocalTaskCount>> registries. It then calculates the exact number of executors which is the input `numExecutors` and <<executorsPendingToRemove, the executors pending removal>> decreased by the number of <<numExistingExecutors, already-assigned executors>>.

If `numExecutors` is negative, a `IllegalArgumentException` is thrown:

```
Attempted to request a negative number of executor(s) [numExecutors] from the cluster manager. Please specify a positive number!
```

NOTE: It is a final method that no other scheduler backends could customize further.

NOTE: The method is a synchronized block that makes multiple concurrent requests be handled in a serial fashion, i.e. one by one.

=== [[minRegisteredRatio]] `minRegisteredRatio` Property

[source, scala]
----
minRegisteredRatio: Double
----

`minRegisteredRatio` returns a ratio between `0` and `1` (inclusive). You can use <<spark.scheduler.minRegisteredResourcesRatio, spark.scheduler.minRegisteredResourcesRatio>> to control the value.

=== [[start]] Starting `CoarseGrainedSchedulerBackend` -- `start` Method

`start` initializes <<CoarseGrainedScheduler, CoarseGrainedScheduler RPC Endpoint>>.

.CoarseGrainedScheduler Endpoint
image::images/CoarseGrainedScheduler-rpc-endpoint.png[align="center"]

NOTE: `start` is part of the link:spark-scheduler-backends.adoc#contract[SchedulerBackend Contract].

NOTE: The RPC Environment is passed on as an constructor parameter.

=== [[stop]] Stopping `CoarseGrainedSchedulerBackend` -- `stop` Method

`stop` method <<stopExecutors, stops executors>> and <<CoarseGrainedScheduler, CoarseGrainedScheduler RPC endpoint>>.

NOTE: `stop` is part of the link:spark-scheduler-backends.adoc#contract[SchedulerBackend Contract].

NOTE: When called with no `driverEndpoint` both `stop()` and `stopExecutors()` do nothing. `driverEndpoint` is initialized in `start` and the initialization order matters.

It prints INFO to the logs:

```
INFO Shutting down all executors
```

It then sends <<StopExecutors, StopExecutors>> message to `driverEndpoint`. It disregards the response.

It sends <<StopDriver, StopDriver>> message to `driverEndpoint`. It disregards the response.

=== [[defaultParallelism]] Compute Default Level of Parallelism -- `defaultParallelism` Method

The default parallelism is controlled by link:spark-rdd-partitions.adoc#spark_default_parallelism[spark.default.parallelism] or is at least `2` or `totalCoreCount`.

NOTE: `defaultParallelism` is part of the link:spark-scheduler-backends.adoc#contract[SchedulerBackend Contract].

=== [[reviveOffers]] Reviving Offers -- `reviveOffers` Method

NOTE: `reviveOffers` is part of the link:spark-scheduler-backends.adoc#contract[SchedulerBackend Contract].

`reviveOffers` simply sends a <<ReviveOffers, ReviveOffers>> message to <<driverEndpoint, driverEndpoint>> (so it is processed asynchronously, i.e. on a separate thread, later on).

.Reviving Offers by CoarseGrainedExecutorBackend
image::images/CoarseGrainedExecutorBackend-reviveOffers.png[align="center"]

=== [[killTask]] Killing Task -- `killTask` Method

`killTask` simply sends a <<KillTask, KillTask>> message to <<driverEndpoint, driverEndpoint>>.

CAUTION: FIXME Image

NOTE: `killTask` is part of the link:spark-scheduler-backends.adoc#contract[SchedulerBackend Contract].

=== [[isReady]] Delaying Task Launching -- `isReady` Method

`isReady` is a custom implementation of link:spark-scheduler-backends.adoc#contract[isReady from the `SchedulerBackend` Contract] that allows to delay task launching until sufficient resources are registered or <<settings, spark.scheduler.maxRegisteredResourcesWaitingTime>> passes.

NOTE: `isReady` is used exclusively by link:spark-taskschedulerimpl.adoc#waitBackendReady[TaskSchedulerImpl.waitBackendReady].

It starts checking whether there are sufficient resources available (using <<sufficientResourcesRegistered, sufficientResourcesRegistered>> method).

NOTE: By default `sufficientResourcesRegistered` always responds that sufficient resources are available.

If <<sufficientResourcesRegistered, sufficient resources are available>>, you should see the following INFO message in the logs:

[options="wrap"]
----
INFO SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: [minRegisteredRatio]
----

The method finishes returning `true`.

NOTE: `minRegisteredRatio` in the logs above is in the range 0 to 1 (uses <<settings, spark.scheduler.minRegisteredResourcesRatio>>) to denote the minimum ratio of registered resources to total expected resources before submitting tasks.

In case there are no sufficient resources available yet (the above requirement does not hold), it checks whether the time from the startup (as `createTime`) passed <<settings, spark.scheduler.maxRegisteredResourcesWaitingTime>> to give a way to submit tasks (despite `minRegisteredRatio` not being reached yet).

You should see the following INFO message in the logs:

[options="wrap"]
----
INFO SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: [maxRegisteredWaitingTimeMs](ms)
----

The method finishes returning `true`.

Otherwise, when <<sufficientResourcesRegistered, no sufficient resources are available>> and <<spark.scheduler.maxRegisteredResourcesWaitingTime, maxRegisteredWaitingTimeMs>> has not been passed, it finishes returning `false`.

=== [[sufficientResourcesRegistered]] `sufficientResourcesRegistered` Method

`sufficientResourcesRegistered` always responds that sufficient resources are available.

=== [[stopExecutors]] Stop All Executors -- `stopExecutors` Method

`stopExecutors` sends a blocking <<StopExecutors, StopExecutors>> message to <<driverEndpoint, driverEndpoint>> (if already initialized).

NOTE: It is called exclusively while `CoarseGrainedSchedulerBackend` is <<stop, being stopped>>.

You should see the following INFO message in the logs:

```
INFO CoarseGrainedSchedulerBackend: Shutting down all executors
```

=== [[reset]] Reset State -- `reset` Method

`reset` resets the internal state:

1. Sets `numPendingExecutors` to 0
2. Clears `executorsPendingToRemove`
3. Sends a blocking <<RemoveExecutor, RemoveExecutor>> message to <<driverEndpoint, driverEndpoint>> for every executor (in the internal `executorDataMap`) to inform it about `SlaveLost` with the message:
+
```
Stale executor after cluster manager re-registered.
```

`reset` is a method that is defined in `CoarseGrainedSchedulerBackend`, but used and overriden exclusively by link:yarn/spark-yarn-yarnschedulerbackend.adoc[YarnSchedulerBackend].

=== [[removeExecutor]] Remove Executor -- `removeExecutor` Method

[source, scala]
----
removeExecutor(executorId: String, reason: ExecutorLossReason)
----

`removeExecutor` sends a blocking <<RemoveExecutor, RemoveExecutor>> message to <<driverEndpoint, driverEndpoint>>.

NOTE: It is called by subclasses link:spark-standalone.adoc#SparkDeploySchedulerBackend[SparkDeploySchedulerBackend], link:spark-mesos/spark-mesos.adoc#CoarseMesosSchedulerBackend[CoarseMesosSchedulerBackend], and link:yarn/spark-yarn-yarnschedulerbackend.adoc[YarnSchedulerBackend].

=== [[driverEndpoint]][[CoarseGrainedScheduler]] CoarseGrainedScheduler RPC Endpoint -- `driverEndpoint`

When <<start, CoarseGrainedSchedulerBackend starts>>, it registers *CoarseGrainedScheduler* RPC endpoint to be the driver's communication endpoint.

Internally, it is a <<DriverEndpoint, DriverEndpoint>> object available as the `driverEndpoint` internal field.

NOTE: `CoarseGrainedSchedulerBackend` is created while link:spark-sparkcontext-creating-instance-internals.adoc#createTaskScheduler[SparkContext is being created] that in turn lives inside a link:spark-driver.adoc[Spark driver]. That explains the name `driverEndpoint` (at least partially).

It is called *standalone scheduler's driver endpoint* internally.

It tracks:

* Executor addresses (host and port) for executors (`addressToExecutorId`) - it is set when an executor connects to register itself. See <<RegisterExecutor, RegisterExecutor>> RPC message.
* Total number of core count (`totalCoreCount`) - the sum of all cores on all executors. See <<RegisterExecutor, RegisterExecutor>> RPC message.
* The number of executors available (`totalRegisteredExecutors`). See <<RegisterExecutor, RegisterExecutor>> RPC message.
* `ExecutorData` for each registered executor (`executorDataMap`). See <<RegisterExecutor, RegisterExecutor>> RPC message.

It uses `driver-revive-thread` daemon single-thread thread pool for ...FIXME

CAUTION: FIXME A potential issue with `driverEndpoint.asInstanceOf[NettyRpcEndpointRef].toURI` - doubles `spark://` prefix.

* `spark.scheduler.revive.interval` (default: `1s`) - time between reviving offers.

=== [[messages]] RPC Messages

====  KillTask(taskId, executorId, interruptThread)

==== RemoveExecutor

==== [[RetrieveSparkProps]] RetrieveSparkProps

==== [[ReviveOffers]] ReviveOffers

`ReviveOffers` simply passes the call on to <<makeOffers, makeOffers>>.

CAUTION: FIXME When is an executor alive? What other states can an executor be in?

==== [[StatusUpdate]] StatusUpdate

[source, scala]
----
StatusUpdate(
  executorId: String,
  taskId: Long,
  state: TaskState,
  data: SerializableBuffer)
extends CoarseGrainedClusterMessage
----

CAUTION: FIXME

==== [[StopDriver]] StopDriver

`StopDriver` message stops the RPC endpoint.

==== StopExecutors

`StopExecutors` message is receive-reply and blocking. When received, the following INFO message appears in the logs:

```
INFO Asking each executor to shut down
```

It then sends a link:spark-executor-backends-CoarseGrainedExecutorBackend.adoc#StopExecutor[StopExecutor] message to every registered executor (from `executorDataMap`).

==== [[RegisterExecutor]] RegisterExecutor

[source, scala]
----
RegisterExecutor(
  executorId: String,
  executorRef: RpcEndpointRef,
  hostname: String,
  cores: Int,
  logUrls: Map[String, String])
extends CoarseGrainedClusterMessage
----

NOTE: `RegisterExecutor` is sent when link:spark-executor-backends-CoarseGrainedExecutorBackend.adoc#onStart[CoarseGrainedExecutorBackend (RPC Endpoint) starts].

.Executor registration (RegisterExecutor RPC message flow)
image::images/CoarseGrainedSchedulerBackend-RegisterExecutor-event.png[align="center"]

Only one executor can register under `executorId`.

```
INFO Registered executor [executorRef] ([executorAddress]) with ID [executorId]
```

It does internal bookkeeping like updating `addressToExecutorId`, `totalCoreCount`, and `totalRegisteredExecutors`, `executorDataMap`.

When `numPendingExecutors` is more than `0`, the following is printed out to the logs:

```
DEBUG Decremented number of pending executors ([numPendingExecutors] left)
```

It replies with `RegisteredExecutor(executorAddress.host)` (consult link:spark-executor-backends.adoc#messages[RPC Messages] of CoarseGrainedExecutorBackend).

It then announces the new executor by posting link:spark-SparkListener.adoc#SparkListenerExecutorAdded[SparkListenerExecutorAdded] to link:spark-LiveListenerBus.adoc[LiveListenerBus].

Ultimately, <<makeOffers, makeOffers>> is called.

=== [[DriverEndpoint]] DriverEndpoint

`DriverEndpoint` is a link:spark-rpc.adoc#ThreadSafeRpcEndpoint[ThreadSafeRpcEndpoint].

==== [[DriverEndpoint-onDisconnected]] onDisconnected Callback

When called, `onDisconnected` removes the worker from the internal <<addressToExecutorId, addressToExecutorId registry>> (that effectively removes the worker from a cluster).

While removing, it calls <<removeExecutor, removeExecutor>> with the reason being `SlaveLost` and message:

[options="wrap"]
----
Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
----

NOTE: `onDisconnected` is called when a remote host is lost.

==== [[makeOffers]] Making Resource Offers -- `makeOffers` Method

[source, scala]
----
makeOffers(): Unit
----

`makeOffers` is a private method that takes the active executors (out of the <<executorDataMap, executorDataMap>> internal registry) and creates `WorkerOffer` resource offers for each (one per executor with the executor's id, host and free cores).

CAUTION: Only free cores are considered in making offers. Memory is not! Why?!

It then requests link:spark-taskschedulerimpl.adoc#resourceOffers[`TaskSchedulerImpl` to process the resource offers] to create a collection of `TaskDescription` collections that it in turn uses to <<launchTasks, launch tasks>>.

=== [[launchTasks]][[launching-tasks]] Launching Tasks -- `launchTasks` Method

[source, scala]
----
launchTasks(tasks: Seq[Seq[TaskDescription]])
----

`launchTasks` is a private helper method that iterates over `TaskDescription` objects in the `tasks` input collection and ...FIXME

NOTE: `launchTasks` gets called when `CoarseGrainedSchedulerBackend` is <<makeOffers, making resource offers>>.

Internally, it serializes a `TaskDescription` (using the global link:spark-sparkenv.adoc#closureSerializer[closure Serializer]) to a serialized task and checks the size of the serialized format of the task so it is less than `maxRpcMessageSize`.

CAUTION: FIXME Describe `maxRpcMessageSize`.

If the serialized task's size is over the maximum RPC message size, the task's link:spark-tasksetmanager.adoc#abort[`TaskSetManager` is aborted].

CAUTION: FIXME At that point, tasks have their executor assigned. When and how did that happen?

If the serialized task's size is correct, the task's executor is looked up in the internal <<executorDataMap, executorDataMap>> registry to record that the task is about to be launched and the number of free cores of the executor is decremented by the `CPUS_PER_TASK` constant (i.e. link:spark-taskschedulerimpl.adoc#spark_task_cpus[spark.task.cpus]).

NOTE: `ExecutorData` keeps track of the number of free cores of the executor (as `freeCores`) as well as the `RpcEndpointRef` of the executor to send tasks to launch to (as `executorEndpoint`).

You should see the following INFO in the logs:

```
INFO DriverEndpoint: Launching task [taskId] on executor id: [executorId] hostname: [executorHost].
```

Ultimately, `launchTasks` sends a link:spark-executor-backends-CoarseGrainedExecutorBackend.adoc#LaunchTask[LaunchTask] message to the executor's RPC endpoint with the serialized task (wrapped in `SerializableBuffer`).

NOTE: Scheduling in Spark relies on cores only (not memory), i.e. the number of tasks Spark can run on an executor is constrained by the number of cores available only. When submitting Spark application for execution both -- memory and cores -- can be specified explicitly.

=== [[settings]] Settings

.Spark Properties
[frame="topbot",cols="1,1,2",options="header",width="100%"]
|======================
| Spark Property | Default Value | Description
| [[spark_rpc_message_maxSize]] `spark.rpc.message.maxSize` | `128` | Maximum message size (in MB) to allow in "control plane" communication; generally only applies to map output size (serialized) information sent between executors and the driver.

Increase this if you are running jobs with many thousands of map and reduce tasks and see messages about the RPC message size.

| [[spark.scheduler.minRegisteredResourcesRatio]] `spark.scheduler.minRegisteredResourcesRatio` | `0` | Double number between 0 and 1 (including) that controls the minimum ratio of (registered resources / total expected resources) before submitting tasks.

See <<isReady, isReady>> in this document.

| [[spark.scheduler.maxRegisteredResourcesWaitingTime]] `spark.scheduler.maxRegisteredResourcesWaitingTime` | `30s` | Time to wait for sufficient resources available.

See <<isReady, isReady>> in this document.
|======================
