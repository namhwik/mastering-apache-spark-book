== YarnRMClient

`YarnRMClient` is responsible for <<register, registering>> and <<unregister, unregistering>> a Spark application (in the form of link:spark-yarn-applicationmaster.adoc[ApplicationMaster]) with link:spark-yarn-introduction.adoc#ResourceManager[YARN ResourceManager] (and hence _RM_ in the name). It is a mere wrapper for https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html[AMRMClient[ContainerRequest\]] that is started when <<register, registering ApplicationMaster>> (and never stopped explicitly!).

Besides being responsible for <<register, registration>> and <<unregister, unregistration>>, it also knows the <<getAttemptId, application attempt identifiers>> and <<getMaxRegAttempts, tracks the maximum number of attempts to register `ApplicationMaster`>>.

[TIP]
====
Enable `INFO` logging level for `org.apache.spark.deploy.yarn.YarnRMClient` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.deploy.yarn.YarnRMClient=INFO
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[register]] Registering ApplicationMaster with YARN ResourceManager (register method)

To link:spark-yarn-applicationmaster.adoc#registerAM[register `ApplicationMaster`] (for a Spark application) with the YARN ResourceManager, Spark uses `register`.

[source, scala]
----
register(
  driverUrl: String,
  driverRef: RpcEndpointRef,
  conf: YarnConfiguration,
  sparkConf: SparkConf,
  uiAddress: String,
  uiHistoryAddress: String,
  securityMgr: SecurityManager,
  localResources: Map[String, LocalResource]): YarnAllocator
----

`register` instantiates YARN's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html[AMRMClient], initializes it (using `conf` input parameter) and starts immediately. It saves `uiHistoryAddress` input parameter internally for later use.

.Registering ApplicationMaster with YARN ResourceManager
image::../images/spark-yarn-YarnRMClient-register.png[align="center"]

You should see the following INFO message in the logs (in stderr in YARN):

```
INFO YarnRMClient: Registering the ApplicationMaster
```

It then link:++https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html#registerApplicationMaster(java.lang.String, int, java.lang.String)++[registers the application master] on the local host with port `0` and `uiAddress` input parameter for the URL at which the master info can be seen.

The internal `registered` flag is enabled.

Ultimately, it link:spark-yarn-YarnAllocator.adoc#creating-instance[creates a new `YarnAllocator`] with the input parameters of `register` passed in and the just-created YARN https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html[AMRMClient].

=== [[unregister]] Unregistering ApplicationMaster from YARN ResourceManager (unregister method)

[source, scala]
----
unregister(status: FinalApplicationStatus, diagnostics: String = ""): Unit
----

`unregister` unregisters the ApplicationMaster of a Spark application.

It basically checks that <<register, `ApplicationMaster` is registered>> and only when it is requests the internal link:++https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/client/api/AMRMClient.html#unregisterApplicationMaster(org.apache.hadoop.yarn.api.records.FinalApplicationStatus, java.lang.String, java.lang.String)++[AMRMClient to unregister].

`unregister` is called when link:spark-yarn-applicationmaster.adoc#unregister[`ApplicationMaster` wants to unregister].

=== [[getMaxRegAttempts]] Maximum Number of Attempts to Register ApplicationMaster (getMaxRegAttempts method)

[source, scala]
----
getMaxRegAttempts(sparkConf: SparkConf, yarnConf: YarnConfiguration): Int
----

`getMaxRegAttempts` uses link:spark-configuration.adoc[SparkConf] and YARN's https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html[YarnConfiguration] to read configuration settings and return the maximum number of application attempts before link:spark-yarn-applicationmaster.adoc[ApplicationMaster] registration with YARN is considered unsuccessful (and so the Spark application).

It reads YARN's `yarn.resourcemanager.am.max-attempts` (available as https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html#RM_AM_MAX_ATTEMPTS[YarnConfiguration.RM_AM_MAX_ATTEMPTS]) or falls back to https://hadoop.apache.org/docs/current/api/org/apache/hadoop/yarn/conf/YarnConfiguration.html#DEFAULT_RM_AM_MAX_ATTEMPTS[YarnConfiguration.DEFAULT_RM_AM_MAX_ATTEMPTS] (which is `2`).

The return value is the minimum of the configuration settings of YARN and Spark.

=== [[getAttemptId]] Getting ApplicationAttemptId of Spark Application (getAttemptId method)

[source, scala]
----
getAttemptId(): ApplicationAttemptId
----

`getAttemptId` returns YARN's `ApplicationAttemptId` (of the Spark application to which the container was assigned).

Internally, it uses YARN-specific methods like link:spark-yarn-YarnSparkHadoopUtil.adoc#getContainerId[ConverterUtils.toContainerId] and https://hadoop.apache.org/docs/current/api/index.html?org/apache/hadoop/yarn/client/api/YarnClient.html[ContainerId.getApplicationAttemptId].

=== [[getAmIpFilterParams]] getAmIpFilterParams

CAUTION: FIXME
