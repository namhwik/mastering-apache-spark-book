== MemoryStore

`MemoryStore` manages blocks (in the internal <<entries, entries>> registry).

`MemoryStore` requires link:spark-configuration.adoc[SparkConf], link:spark-BlockInfoManager.adoc[BlockInfoManager], link:spark-SerializerManager.adoc[SerializerManager], link:spark-MemoryManager.adoc[MemoryManager] and `BlockEvictionHandler` to be created.

CAUTION: FIXME Where are these dependencies used?

CAUTION: FIXME Where is the `MemoryStore` created? What params provided?

NOTE: `MemoryStore` is a `private[spark]` class.

[TIP]
====
Enable `INFO` or `DEBUG` logging level for `org.apache.spark.storage.memory.MemoryStore` logger to see what happens inside.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.storage.memory.MemoryStore=DEBUG
```

Refer to link:spark-logging.adoc[Logging].
====

=== [[entries]] entries Registry

`entries` is Java's `LinkedHashMap` with the initial capacity of `32`, the load factor of `0.75` and _access-order_ ordering mode (i.e. iteration is in the order in which its entries were last accessed, from least-recently accessed to most-recently).

NOTE: `entries` is Java's https://docs.oracle.com/javase/8/docs/api/java/util/LinkedHashMap.html[java.util.LinkedHashMap].

=== [[putBytes]] putBytes

[source, scala]
----
putBytes[T: ClassTag](
  blockId: BlockId,
  size: Long,
  memoryMode: MemoryMode,
  _bytes: () => ChunkedByteBuffer): Boolean
----

`putBytes` requests `size` memory for the `blockId` block from the current link:spark-MemoryManager.adoc[MemoryManager]. If successful, it registers a `SerializedMemoryEntry` (with the input `_bytes` and `memoryMode`) for `blockId` in the internal <<entries, entries>> registry.

You should see the following INFO message in the logs:

```
INFO Block [blockId] stored as bytes in memory (estimated size [size], free [bytes])
```

`putBytes` returns `true` after `putBytes` stored `blockId`.

=== [[evictBlocksToFreeSpace]] Evicting Blocks to Free Space

CAUTION: FIXME

=== [[remove]] Removing Block

CAUTION: FIXME

=== [[settings]] Settings

==== [[spark.storage.unrollMemoryThreshold]] spark.storage.unrollMemoryThreshold

`spark.storage.unrollMemoryThreshold` (default: `1024 * 1024`) controls...
