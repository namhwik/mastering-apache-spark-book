== [[LogicalPlan]] LogicalPlan -- Logical Query Plan / Logical Operator

`LogicalPlan` is a base Catalyst link:spark-sql-catalyst-QueryPlan.adoc[query plan] for *logical operators* to build a *logical query plan* that, when <<analyzed, analyzed>> and <<resolved, resolved>>, can be resolved to a link:spark-sql-SparkPlan.adoc[physical query plan].

[TIP]
====
Use link:spark-sql-Dataset.adoc#queryExecution[QueryExecution] of a structured query to see the link:spark-sql-QueryExecution.adoc#logical[logical plan].

[source, scala]
----
val q: DataFrame = ...
val plan = q.queryExecution.logical
----
====

[[analyzed]]
`LogicalPlan` can be *analyzed* which is to say that the plan (including children) has gone through analysis and verification.

[source, scala]
----
scala> plan.analyzed
res1: Boolean = true
----

[[resolved]]
A logical plan can also be *resolved* to a specific schema.

[source, scala]
----
scala> plan.resolved
res2: Boolean = true
----

A logical plan knows the size of objects that are results of query operators, like `join`, through `Statistics` object.

[source, scala]
----
scala> val stats = plan.statistics
stats: org.apache.spark.sql.catalyst.plans.logical.Statistics = Statistics(8,false)
----

[[maxRows]]
A logical plan knows the maximum number of records it can compute.

[source, scala]
----
scala> val maxRows = plan.maxRows
maxRows: Option[Long] = None
----

`LogicalPlan` can be <<isStreaming, streaming>> if it contains one or more link:spark-sql-streaming-source.adoc[structured streaming sources].

[[specialized-logical-plans]]
.Logical Operators / Specialized Logical Plans
[cols="1,2",options="header",width="100%"]
|===
| LogicalPlan
| Description

| [[LeafNode]] `LeafNode`
| Logical operator with no child operators

| [[UnaryNode]] `UnaryNode`
| Logical plan with a single child (logical plan).

| [[BinaryNode]] `BinaryNode`
| Logical operator with two child operators

| <<Command, Command>>
|

| link:spark-sql-LogicalPlan-RunnableCommand.adoc[RunnableCommand]
|
|===

[[internal-registries]]
.LogicalPlan's Internal Registries and Counters (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[statsCache]] `statsCache`
| Cached plan statistics (as `Statistics`) of the `LogicalPlan`

Computed and cached in <<stats, stats>>.

Used in <<stats, stats>> and <<verboseStringWithSuffix, verboseStringWithSuffix>>.

Reset in <<invalidateStatsCache, invalidateStatsCache>>
|===

=== [[stats]] Getting Cached or Calculating Estimated Statistics -- `stats` Method

[source, scala]
----
stats(conf: CatalystConf): Statistics
----

`stats` returns the <<statsCache, cached plan statistics>> or <<computeStats, computes a new one>> (and caches it as <<statsCache, statsCache>>).

[NOTE]
====
`stats` is used when:

* A `LogicalPlan` <<computeStats, computes `Statistics`>>
* `QueryExecution` link:spark-sql-QueryExecution.adoc#completeString[builds complete text representation]
* `JoinSelection` link:spark-sql-SparkStrategy-JoinSelection.adoc#canBroadcast[checks whether a plan can be broadcast] et al
* link:spark-sql-Optimizer-CostBasedJoinReorder.adoc[CostBasedJoinReorder] attempts to reorder inner joins
* `LimitPushDown` link:spark-sql-Optimizer-LimitPushDown.adoc#apply[is executed] (for link:spark-sql-joins.adoc#FullOuter[FullOuter] join)
* `AggregateEstimation` estimates `Statistics`
* `FilterEstimation` estimates child `Statistics`
* `InnerOuterEstimation` estimates `Statistics` of the left and right sides of a join
* `LeftSemiAntiEstimation` estimates `Statistics`
* `ProjectEstimation` estimates `Statistics`
====

=== [[invalidateStatsCache]] `invalidateStatsCache` method

CAUTION: FIXME

=== [[verboseStringWithSuffix]] `verboseStringWithSuffix` method

CAUTION: FIXME

=== [[resolveQuoted]] `resolveQuoted` method

CAUTION: FIXME

=== [[setAnalyzed]] `setAnalyzed` method

CAUTION: FIXME

=== [[Command]] `Command` -- Logical Commands

`Command` is the base for <<LeafNode, leaf logical plans>> that represent non-query commands to be executed by the system. It defines `output` to return an empty collection of link:spark-sql-Expression-Attribute.adoc[Attributes].

Known commands are:

1. `CreateTable`
2. Any link:spark-sql-LogicalPlan-RunnableCommand.adoc[RunnableCommand]

=== [[isStreaming]] Is Logical Plan Streaming? -- `isStreaming` method

[source, scala]
----
isStreaming: Boolean
----

`isStreaming` is a part of the public API of `LogicalPlan` and is enabled (i.e. `true`) when a logical plan is a link:spark-sql-streaming-source.adoc[streaming source].

By default, it walks over subtrees and calls itself, i.e. `isStreaming`, on every child node to find a streaming source.

[source, scala]
----
val spark: SparkSession = ...

// Regular dataset
scala> val ints = spark.createDataset(0 to 9)
ints: org.apache.spark.sql.Dataset[Int] = [value: int]

scala> ints.queryExecution.logical.isStreaming
res1: Boolean = false

// Streaming dataset
scala> val logs = spark.readStream.format("text").load("logs/*.out")
logs: org.apache.spark.sql.DataFrame = [value: string]

scala> logs.queryExecution.logical.isStreaming
res2: Boolean = true
----

NOTE: Streaming Datasets are part of Structured Streaming.

=== [[computeStats]] Computing Statistics Estimates (of All Child Logical Operators) for Cost-Based Optimizer -- `computeStats` method

[source, scala]
----
computeStats(conf: CatalystConf): Statistics
----

`computeStats` creates a `Statistics` with `sizeInBytes` as a product of <<stats, statistics>> of all link:spark-sql-catalyst-TreeNode.adoc#children[child] logical plans.

For a no-children logical plan, `computeStats` reports a `UnsupportedOperationException`:

```
LeafNode [nodeName] must implement statistics.
```

NOTE: `computeStats` is a `protected` method that logical operators are expected to override to provide their own custom plan statistics calculation.

NOTE: `computeStats` is used exclusively when `LogicalPlan` <<stats, is requested for logical plan statistics estimates>>.
