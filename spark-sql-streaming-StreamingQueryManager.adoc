== StreamingQueryManager -- Streaming Query Management

NOTE: `StreamingQueryManager` is an experimental feature of Spark 2.0.0.

A `StreamingQueryManager` is the Management API for link:spark-sql-streaming-StreamingQuery.adoc[continuous queries] per `SQLContext`.

NOTE: There is a single `StreamingQueryManager` instance per `SQLContext` session.

You can access `StreamingQueryManager` for the current link:spark-sql-sqlcontext.adoc[SQLContext] using link:spark-sql-sqlcontext.adoc#accessing-StreamingQueryManager[SQLContext.streams] method. It is lazily created when a `SQLContext` instance starts.

[source, scala]
----
val queries = spark.streams
----

=== Initialization

`StreamingQueryManager` manages the following instances:

* `StateStoreCoordinatorRef` (as `stateStoreCoordinator`)
* link:spark-sql-streaming-StreamingQueryListenerBus.adoc[StreamingQueryListenerBus] (as `listenerBus`)
* `activeQueries` which is a mutable mapping between query names and `StreamingQuery` objects.

=== [[startQuery]] startQuery

[source, scala]
----
startQuery(name: String,
  checkpointLocation: String,
  df: DataFrame,
  sink: Sink,
  trigger: Trigger = ProcessingTime(0)): StreamingQuery
----

`startQuery` is a `private[sql]` method to start a link:spark-sql-streaming-StreamingQuery.adoc[StreamingQuery].

NOTE: It is called exclusively by link:spark-sql-streaming-DataStreamWriter.adoc#start[DataStreamWriter.start].

NOTE: By default, `trigger` is link:spark-sql-streaming-trigger.adoc#ProcessingTime[ProcessingTime(0)].

`startQuery` makes sure that `activeQueries` internal registry does not contain the query under `name`. It throws an `IllegalArgumentException` if it does.

It transforms the link:spark-sql-LogicalPlan.adoc[LogicalPlan] of the input DataFrame `df` so all link:spark-sql-streaming-streamingrelation.adoc[StreamingRelation] "nodes" become link:spark-sql-streaming-streamingrelation.adoc#StreamingExecutionRelation[StreamingExecutionRelation]. It uses link:spark-sql-datasource.adoc#createSource[DataSource.createSource(metadataPath)] where `metadataPath` is `$checkpointLocation/sources/$nextSourceId`. Otherwise, it returns the `LogicalPlan` untouched.

It finally creates link:spark-sql-streaming-streamexecution.adoc[StreamExecution] and starts it. It also registers the `StreamExecution` instance in `activeQueries` internal registry.

=== [[StreamingQueryManager-active]] Return All Active Continuous Queries per SQLContext

[source, scala]
----
active: Array[StreamingQuery]
----

`active` method returns a collection of link:spark-sql-streaming-StreamingQuery.adoc[StreamingQuery] instances for the current `SQLContext`.

=== [[StreamingQueryManager-get]] Getting Active Continuous Query By Name

[source, scala]
----
get(name: String): StreamingQuery
----

`get` method returns a link:spark-sql-streaming-StreamingQuery.adoc[StreamingQuery] by `name`.

It may throw an `IllegalArgumentException` when no StreamingQuery exists for the `name`.

```
java.lang.IllegalArgumentException: There is no active query with name hello
  at org.apache.spark.sql.StreamingQueryManager$$anonfun$get$1.apply(StreamingQueryManager.scala:59)
  at org.apache.spark.sql.StreamingQueryManager$$anonfun$get$1.apply(StreamingQueryManager.scala:59)
  at scala.collection.MapLike$class.getOrElse(MapLike.scala:128)
  at scala.collection.AbstractMap.getOrElse(Map.scala:59)
  at org.apache.spark.sql.StreamingQueryManager.get(StreamingQueryManager.scala:58)
  ... 49 elided
```

=== [[addListener]][[removeListener]] StreamingQueryListener Management - Adding or Removing Listeners

* `addListener(listener: StreamingQueryListener): Unit` adds `listener` to the internal `listenerBus`.
* `removeListener(listener: StreamingQueryListener): Unit` removes `listener` from the internal `listenerBus`.

=== [[postListenerEvent]] postListenerEvent

[source, scala]
----
postListenerEvent(event: StreamingQueryListener.Event): Unit
----

`postListenerEvent` posts a `StreamingQueryListener.Event` to `listenerBus`.

=== [[StreamingQueryListener]] StreamingQueryListener

CAUTION: FIXME

`StreamingQueryListener` is an interface for listening to query life cycle events, i.e. a query start, progress and termination events.

=== [[lastTerminatedQuery]] lastTerminatedQuery - internal barrier

CAUTION: FIXME Why is `lastTerminatedQuery` needed?

Used in:

* `awaitAnyTermination`
* `awaitAnyTermination(timeoutMs: Long)`

They all wait `10` millis before doing the check of `lastTerminatedQuery` being non-null.

It is set in:

* `resetTerminated()` resets `lastTerminatedQuery`, i.e. sets it to `null`.
* `notifyQueryTermination(terminatedQuery: StreamingQuery)` sets `lastTerminatedQuery` to be `terminatedQuery` and notifies all the threads that wait on `awaitTerminationLock`.
+
It is called from link:spark-sql-streaming-streamexecution.adoc#runBatches[StreamExecution.runBatches].
