== [[WindowFunctionFrame]] WindowFunctionFrame

`WindowFunctionFrame` is a <<contract, contract>> for...FIXME

[[implementations]]
.WindowFunctionFrame's Implementations
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| `OffsetWindowFunctionFrame`
|

| [[SlidingWindowFunctionFrame]] `SlidingWindowFunctionFrame`
|

| `UnboundedFollowingWindowFunctionFrame`
|

| `UnboundedPrecedingWindowFunctionFrame`
|

| <<UnboundedWindowFunctionFrame, UnboundedWindowFunctionFrame>>
|
|===

=== [[UnboundedWindowFunctionFrame]] `UnboundedWindowFunctionFrame`

`UnboundedWindowFunctionFrame` is a <<WindowFunctionFrame, WindowFunctionFrame>> that gives the same value for every row in a partition.

`UnboundedWindowFunctionFrame` is <<UnboundedWindowFunctionFrame-creating-instance, created>> for link:spark-sql-Expression-AggregateFunction.adoc[AggregateFunctions] (in link:spark-sql-Expression-AggregateExpression.adoc[AggregateExpression]s) or link:spark-sql-Expression-AggregateWindowFunction.adoc[AggregateWindowFunctions] with no frame defined (i.e. no `rowsBetween` or `rangeBetween`) that boils down to using the link:spark-sql-SparkPlan-WindowExec.adoc#entire-partition-frame[entire partition frame].

[[UnboundedWindowFunctionFrame-creating-instance]]
`UnboundedWindowFunctionFrame` takes the following when created:

* [[UnboundedWindowFunctionFrame-target]] Target link:spark-sql-InternalRow.adoc[InternalRow]
* [[UnboundedWindowFunctionFrame-processor]] link:spark-sql-AggregateProcessor.adoc[AggregateProcessor]

==== [[UnboundedWindowFunctionFrame-prepare]] `prepare` Method

[source, scala]
----
prepare(rows: ExternalAppendOnlyUnsafeRowArray): Unit
----

`prepare` requests <<UnboundedWindowFunctionFrame-processor, AggregateProcessor>> to link:spark-sql-AggregateProcessor.adoc#initialize[initialize] passing in the number of `UnsafeRows` in the input `ExternalAppendOnlyUnsafeRowArray`.

`prepare` then requests `ExternalAppendOnlyUnsafeRowArray` to link:spark-sql-ExternalAppendOnlyUnsafeRowArray.adoc#generateIterator[generate an interator].

In the end, `prepare` requests <<UnboundedWindowFunctionFrame-processor, AggregateProcessor>> to link:spark-sql-AggregateProcessor.adoc#update[update] passing in every `UnsafeRow` in the iterator one at a time.

==== [[UnboundedWindowFunctionFrame-write]] `write` Method

[source, scala]
----
write(index: Int, current: InternalRow): Unit
----

`write` simply requests <<UnboundedWindowFunctionFrame-processor, AggregateProcessor>> to link:spark-sql-AggregateProcessor.adoc#evaluate[evaluate] the <<UnboundedWindowFunctionFrame-target, target InternalRow>>.

=== [[contract]] WindowFunctionFrame Contract

[source, scala]
----
package org.apache.spark.sql.execution.window

abstract class WindowFunctionFrame {
  def prepare(rows: ExternalAppendOnlyUnsafeRowArray): Unit
  def write(index: Int, current: InternalRow): Unit
}
----

NOTE: `WindowFunctionFrame` is a `private[window]` contract.

.WindowFunctionFrame Contract
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[prepare]] `prepare`
| Used exclusively when `WindowExec` operator link:spark-sql-SparkPlan-WindowExec.adoc#fetchNextPartition[fetches all UnsafeRows for a partition] (passing in link:spark-sql-ExternalAppendOnlyUnsafeRowArray.adoc[ExternalAppendOnlyUnsafeRowArray] with all `UnsafeRows`).

| [[write]] `write`
| Used exclusively when the link:spark-sql-SparkPlan-WindowExec.adoc#iterator[Iterator[InternalRow\]] (from link:spark-sql-SparkPlan-WindowExec.adoc#doExecute[executing] `WindowExec`) is link:spark-sql-SparkPlan-WindowExec.adoc#next[requested a next row].
|===
