== Schema -- Structure of Records

A *schema* is the description of the structure of your records (which together create a link:spark-sql-dataset.adoc[Dataset] in Spark SQL). It can be *implicit* (and <<implicit-schema, inferred at runtime>>) or *explicit* (and known at compile time).

A schema is described using <<StructType, StructType>> which is a collection of <<StructField, StructField>> objects. `StructType` and `StructField` belong to the `org.apache.spark.sql.types` package.

[source, scala]
----
import org.apache.spark.sql.types.StructType
val schemaUntyped = new StructType()
  .add("a", "int")
  .add("b", "string")
----

You can use the canonical string representation of SQL types to describe the types in a schema (that is inherently untyped at compile type) or use type-safe types from the `org.apache.spark.sql.types` package.

[source, scala]
----
// it is equivalent to the above expression
import org.apache.spark.sql.types.{IntegerType, StringType}
val schemaTyped = new StructType()
  .add("a", IntegerType)
  .add("b", StringType)
----

TIP: Read up on link:spark-sql-sql-parsers.adoc#CatalystSqlParser[SQL Parser Framework] in Spark SQL to learn about `CatalystSqlParser` that is responsible for parsing data types.

<<StructType, StructType>> offers <<printTreeString, printTreeString>> that make presenting the schema more user-friendly.

[source, scala]
----
scala> schemaTyped.printTreeString
root
 |-- a: integer (nullable = true)
 |-- b: string (nullable = true)

scala> println(schema1.prettyJson)
{
 "type" : "struct",
 "fields" : [ {
   "name" : "a",
   "type" : "integer",
   "nullable" : true,
   "metadata" : { }
 }, {
   "name" : "b",
   "type" : "string",
   "nullable" : true,
   "metadata" : { }
 } ]
}
----

=== [[StructType]] StructType Data Type

`StructType` is a built-in link:spark-sql-DataType.adoc[data type] in Spark SQL to represent a collection of <<StructField, StructFields>>.

[NOTE]
====
`StructType` is a `Seq[StructField]` and therefore all things `Seq` apply equally here.

[source, scala]
----
scala> schemaTyped.foreach(println)
StructField(a,IntegerType,true)
StructField(b,StringType,true)
----

Read the official documentation of http://www.scala-lang.org/api/current/scala/collection/Seq.html[scala.collection.Seq].
====

You can compare two `StructType` instances to see whether they are equal.

[source, scala]
----
import org.apache.spark.sql.types.StructType

val schemaUntyped = new StructType()
  .add("a", "int")
  .add("b", "string")

import org.apache.spark.sql.types.{IntegerType, StringType}
val schemaTyped = new StructType()
  .add("a", IntegerType)
  .add("b", StringType)

scala> schemaUntyped == schemaTyped
res0: Boolean = true
----

`StructType` <<sql, presents itself>> as `<struct>` or `STRUCT` in query plans or SQL.

==== [[add]] Adding Fields to Schema (add methods)

You can add a new `StructField` to your `StructType`. There are different variants of `add` method that all make for a new `StructType` with the field added.

[source, scala]
----
add(field: StructField): StructType
add(name: String, dataType: DataType): StructType
add(name: String, dataType: DataType, nullable: Boolean): StructType
add(
  name: String,
  dataType: DataType,
  nullable: Boolean,
  metadata: Metadata): StructType
add(
  name: String,
  dataType: DataType,
  nullable: Boolean,
  comment: String): StructType
add(name: String, dataType: String): StructType
add(name: String, dataType: String, nullable: Boolean): StructType
add(
  name: String,
  dataType: String,
  nullable: Boolean,
  metadata: Metadata): StructType
add(
  name: String,
  dataType: String,
  nullable: Boolean,
  comment: String): StructType
----

==== [[sql]][[catalogString]][[simpleString]] DataType Name Conversions

[source, scala]
----
simpleString: String
catalogString: String
sql: String
----

`StructType` as a custom `DataType` is used in query plans or SQL. It can present itself using `simpleString`, `catalogString` or `sql` (see link:spark-sql-DataType.adoc#contract[DataType Contract]).

[source, scala]
----
scala> schemaTyped.simpleString
res0: String = struct<a:int,b:string>

scala> schemaTyped.catalogString
res1: String = struct<a:int,b:string>

scala> schemaTyped.sql
res2: String = STRUCT<`a`: INT, `b`: STRING>
----

==== [[apply]] Accessing StructField (apply method)

[source, scala]
----
apply(name: String): StructField
----

`StructType` defines its own `apply` method that gives you an easy access to a `StructField` by name.

[source, scala]
----
scala> schemaTyped.printTreeString
root
 |-- a: integer (nullable = true)
 |-- b: string (nullable = true)

scala> schemaTyped("a")
res4: org.apache.spark.sql.types.StructField = StructField(a,IntegerType,true)
----

==== [[apply-seq]] Creating StructType from Existing StructType (apply method)

[source, scala]
----
apply(names: Set[String]): StructType
----

This variant of `apply` lets you create a `StructType` out of an existing `StructType` with the `names` only.

[source, scala]
----
scala> schemaTyped(names = Set("a"))
res0: org.apache.spark.sql.types.StructType = StructType(StructField(a,IntegerType,true))
----

It will throw an `IllegalArgumentException` exception when a field could not be found.

[source, scala]
----
scala> schemaTyped(names = Set("a", "c"))
java.lang.IllegalArgumentException: Field c does not exist.
  at org.apache.spark.sql.types.StructType.apply(StructType.scala:275)
  ... 48 elided
----

==== [[printTreeString]] Printing Out Schema (printTreeString method)

[source, scala]
----
printTreeString(): Unit
----

`printTreeString` prints out the schema to standard output.

[source, scala]
----
scala> schemaTyped.printTreeString
root
 |-- a: integer (nullable = true)
 |-- b: string (nullable = true)
----

Internally, it uses `treeString` method to build the tree and then `println` it.

=== [[StructField]] StructField

A `StructField` describes a single field in a `StructType`. It has a name, the type and whether or not it be empty, and an optional metadata and a comment.

A comment is a part of metadata under `comment` key and is used to build a Hive column or when describing a table.

[source, scala]
----
scala> schemaTyped("a").getComment
res0: Option[String] = None

scala> schemaTyped("a").withComment("this is a comment").getComment
res1: Option[String] = Some(this is a comment)
----

=== [[implicit-schema]] Implicit Schema

[source, scala]
----
val df = Seq((0, s"""hello\tworld"""), (1, "two  spaces inside")).toDF("label", "sentence")

scala> df.printSchema
root
 |-- label: integer (nullable = false)
 |-- sentence: string (nullable = true)

scala> df.schema
res0: org.apache.spark.sql.types.StructType = StructType(StructField(label,IntegerType,false), StructField(sentence,StringType,true))

scala> df.schema("label").dataType
res1: org.apache.spark.sql.types.DataType = IntegerType
----
