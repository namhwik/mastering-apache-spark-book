== [[ResultTask]] ResultTask

`ResultTask` is a link:spark-taskscheduler-tasks.adoc[Task] that <<runTask, computes FIXME>>.

<<creating-instance, `ResultTask` is created>> exclusively when link:spark-dagscheduler.adoc#submitMissingTasks[`DAGScheduler` submits missing tasks for a `ResultStage`].

[[internal-registries]]
.ResultTask's Internal Registries and Counters
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[preferredLocs]] `preferredLocs`
| Corresponds directly to unique entries in <<locs, locs>> with the only rule that when `locs` is not defined, it is empty, i.e. no task location preferences are defined.

Initialized when <<creating-instance, `ResultTask` is created>>.

Used exclusively when `ResultTask` is requested for <<preferredLocations, preferred task locations>>.
|===

=== [[runTask]] `runTask` Method

[source, scala]
----
runTask(context: TaskContext): U
----

NOTE: `U` is the type of a result as defined when <<creating-instance, `ResultTask` is created>>.

CAUTION: FIXME

=== [[creating-instance]] Creating ResultTask Instance

`ResultTask` takes the following when created:

* `stageId` -- the stage the task is executed for
* `stageAttemptId` -- the stage attempt id
* [[taskBinary]] link:spark-broadcast.adoc[Broadcast variable] with the serialized task (as `Array[Byte]`). The broadcast contains of a serialized pair of `RDD` and the function to execute.
* [[partition]] link:spark-rdd-Partition.adoc[Partition] to compute
* [[locs]] Collection of `TaskLocation`
* [[outputId]] `outputId`
* [[localProperties]] local `Properties`
* [[serializedTaskMetrics]] The stage's serialized link:spark-taskscheduler-taskmetrics.adoc[TaskMetrics] (as `Array[Byte]`)
* [[jobId]] (optional) link:spark-dagscheduler-jobs.adoc[Job] id
* [[appId]] (optional) Application id
* [[appAttemptId]] (optional) Application attempt id

`ResultTask` initializes the <<internal-registries, internal registries and counters>>.

=== [[preferredLocations]] `preferredLocations` Method

[source, scala]
----
preferredLocations: Seq[TaskLocation]
----

NOTE: `preferredLocations` is a part of link:spark-taskscheduler-tasks.adoc#contract[Task contract] to...FIXME

`preferredLocations` simply returns <<preferredLocs, preferredLocs>> internal property.
