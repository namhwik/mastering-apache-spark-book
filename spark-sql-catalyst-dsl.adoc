== [[dsl]] Catalyst DSL -- Implicit Conversions for Catalyst Data Structures

*package object dsl* is a <<implicit-conversions, collection of implicit conversions>> that create a DSL for constructing Catalyst data structures, i.e. link:spark-sql-Expression.adoc[expressions] and link:spark-sql-LogicalPlan.adoc[logical plans].

[NOTE]
====
Most implicit conversions from `package object dsl` interfere with the implicits conversions from `SQLImplicits` that are imported automatically in `spark-shell` as `spark.implicits._`.

```
scala> 'hello.decimal
<console>:30: error: type mismatch;
 found   : Symbol
 required: ?{def decimal: ?}
Note that implicit conversions are not applicable because they are ambiguous:
 both method symbolToColumn in class SQLImplicits of type (s: Symbol)org.apache.spark.sql.ColumnName
 and method DslSymbol in trait ExpressionConversions of type (sym: Symbol)org.apache.spark.sql.catalyst.dsl.expressions.DslSymbol
 are possible conversion functions from Symbol to ?{def decimal: ?}
       'hello.decimal
       ^
<console>:30: error: value decimal is not a member of Symbol
       'hello.decimal
              ^
```
====

[[example]]
[source, scala]
----
import org.apache.spark.sql.catalyst.dsl.expressions._
import org.apache.spark.sql.catalyst.dsl.plans._

// ExpressionConversions

import org.apache.spark.sql.catalyst.expressions.Literal
scala> val trueLit: Literal = true
trueLit: org.apache.spark.sql.catalyst.expressions.Literal = true

import org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute
scala> val name: UnresolvedAttribute = 'name
name: org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute = 'name

// NOTE: This conversion may not work, e.g. in spark-shell
// There is another implicit conversion StringToColumn in SQLImplicits
// It is automatically imported in spark-shell
// See :imports
val id: UnresolvedAttribute = $"id"

import org.apache.spark.sql.catalyst.expressions.Expression
scala> val expr: Expression = sum('id)
expr: org.apache.spark.sql.catalyst.expressions.Expression = sum('id)

// implicit class DslSymbol
scala> 'hello.s
res2: String = hello

scala> 'hello.attr
res4: org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute = 'hello

// implicit class DslString
scala> "helo".expr
res0: org.apache.spark.sql.catalyst.expressions.Expression = helo

scala> "helo".attr
res1: org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute = 'helo

// plans

scala> val t1 = table("t1")
t1: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
'UnresolvedRelation `t1`

scala> val p = t1.select('*).serialize[String].where('id % 2 == 0)
p: org.apache.spark.sql.catalyst.plans.logical.LogicalPlan =
'Filter false
+- 'SerializeFromObject [staticinvoke(class org.apache.spark.unsafe.types.UTF8String, StringType, fromString, input[0, java.lang.String, true], true) AS value#1]
   +- 'Project ['*]
      +- 'UnresolvedRelation `t1`

// FIXME Does not work because SimpleAnalyzer's catalog is empty
// the p plan references a t1 table
import org.apache.spark.sql.catalyst.analysis.SimpleAnalyzer
scala> p.analyze
----

[[implicit-conversions]]
.Catalyst DSL's Implicit Conversions (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Name
| Description

| [[ExpressionConversions]] `ExpressionConversions`
a|

* Adds <<ImplicitOperators, ImplicitOperators>> operators to link:spark-sql-Expression.adoc[Catalyst expressions]

* Converts Scala native types (e.g. `Boolean`, `Long`, `String`, `Date`, `Timestamp`) and Spark SQL types (i.e. `Decimal`) to link:spark-sql-Expression-Literal.adoc[Literal expressions]

* Converts Scala's `Symbol` to `UnresolvedAttribute` and `AttributeReference` expressions

* Converts `$"col name"` to an `UnresolvedAttribute` expression

* Adds aggregate and non-aggregate functions to link:spark-sql-Expression.adoc[Catalyst expressions] (e.g. `sum`, `count`, `upper`, `star`, `callFunction`, `windowSpec`, `windowExpr`)

* Creates `UnresolvedFunction` (`function` operator) and link:spark-sql-Expression-BoundReference.adoc[BoundReference] (`at` operator) expressions

| [[ImplicitOperators]] `ImplicitOperators`
| Operators for link:spark-sql-Expression.adoc[expressions]

| [[plans]] `plans`
a|

* `table` to create a link:spark-sql-LogicalPlan-UnresolvedRelation.adoc[UnresolvedRelation logical plan]

* [[DslLogicalPlan]] Logical operators (e.g. `select`, `where`, `filter`, `serialize`, `join`, `groupBy`, `window`, `generate`)
|===
