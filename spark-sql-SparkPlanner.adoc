== [[SparkPlanner]] SparkPlanner -- Query Planner with no Hive Support

`SparkPlanner` is a concrete Catalyst link:spark-sql-catalyst-QueryPlanner.adoc[query planner] that converts a link:spark-sql-LogicalPlan.adoc[logical plan] to one or more link:spark-sql-SparkPlan.adoc[physical plans] using <<strategies, execution planning strategies>> with support for <<extraStrategies, extra strategies>> (by means of <<experimentalMethods, ExperimentalMethods>>) and <<extraPlanningStrategies, extraPlanningStrategies>>.

NOTE: `SparkPlanner` is expected to plan (aka _generate_) at least one link:spark-sql-SparkPlan.adoc[physical plan] for a link:spark-sql-LogicalPlan.adoc[logical plan].

`SparkPlanner` is available as link:spark-sql-SessionState.adoc#planner[planner] of a `SessionState`.

[source, scala]
----
val spark: SparkSession = ...
spark.sessionState.planner
----

[[strategies]]
.SparkPlanner's Execution Planning Strategies (in execution order)
[cols="1,2",options="header",width="100%"]
|===
| SparkStrategy
| Description

| [[extraStrategies]] ``ExperimentalMethods``'s link:spark-sql-ExperimentalMethods.adoc#extraStrategies[extraStrategies]
|

| <<extraPlanningStrategies, extraPlanningStrategies>>
| Extension point for extra link:spark-sql-SparkStrategy.adoc[planning strategies]

| link:spark-sql-SparkStrategy-FileSourceStrategy.adoc[FileSourceStrategy]
|

| link:spark-sql-SparkStrategy-DataSourceStrategy.adoc[DataSourceStrategy]
|

| `SpecialLimits`
|

| link:spark-sql-SparkStrategy-Aggregation.adoc[Aggregation]
|

| link:spark-sql-SparkStrategy-JoinSelection.adoc[JoinSelection]
|

| link:spark-sql-SparkStrategy-InMemoryScans.adoc[InMemoryScans]
|

| link:spark-sql-SparkStrategy-BasicOperators.adoc[BasicOperators]
|
|===

NOTE: `SparkPlanner` extends link:spark-sql-SparkStrategies.adoc[SparkStrategies] abstract class.

=== [[creating-instance]] Creating SparkPlanner Instance

`SparkPlanner` takes the following when created:

* [[sparkContext]] link:spark-SparkContext.adoc[SparkContext]
* [[conf]] link:spark-sql-SQLConf.adoc[SQLConf]
* [[experimentalMethods]] link:spark-sql-ExperimentalMethods.adoc[ExperimentalMethods]

[NOTE]
====
`SparkPlanner` is <<creating-instance, created>> in:

* link:spark-sql-BaseSessionStateBuilder.adoc[BaseSessionStateBuilder]
* `HiveSessionStateBuilder`
* Structured Streaming's `IncrementalExecution`
====

=== [[extraPlanningStrategies]] Extension Point for Extra Planning Strategies -- `extraPlanningStrategies` Method

[source, scala]
----
extraPlanningStrategies: Seq[Strategy] = Nil
----

`extraPlanningStrategies` is an extension point to register extra link:spark-sql-SparkStrategy.adoc[planning strategies] with the query planner.

NOTE: `extraPlanningStrategies` are executed after <<extraStrategies, extraStrategies>>.

[NOTE]
====
`extraPlanningStrategies` is used when `SparkPlanner` <<strategies, is requested for planning strategies>>.

`extraPlanningStrategies` is overriden in the `SessionState` builders -- link:spark-sql-BaseSessionStateBuilder.adoc[BaseSessionStateBuilder] and `HiveSessionStateBuilder`.
====

=== [[collectPlaceholders]] Collecting PlanLater Physical Operators -- `collectPlaceholders` Method

[source, scala]
----
collectPlaceholders(plan: SparkPlan): Seq[(SparkPlan, LogicalPlan)]
----

`collectPlaceholders` collects all link:spark-sql-SparkStrategy.adoc#PlanLater[PlanLater] physical operators in the `plan` link:spark-sql-SparkPlan.adoc[physical plan].

NOTE: `collectPlaceholders` is a part of link:spark-sql-catalyst-QueryPlanner.adoc#collectPlaceholders[QueryPlanner Contract].

=== [[prunePlans]] Pruning "Bad" Physical Plans -- `prunePlans` Method

[source, scala]
----
prunePlans(plans: Iterator[SparkPlan]): Iterator[SparkPlan]
----

`prunePlans` gives the input `plans` link:spark-sql-SparkPlan.adoc[physical plans] back (i.e. with no changes).

NOTE: `prunePlans` is a part of link:spark-sql-catalyst-QueryPlanner.adoc#prunePlans[QueryPlanner Contract] to remove somehow "bad" plans.

=== [[pruneFilterProject]] `pruneFilterProject` Method

CAUTION: FIXME

NOTE: `pruneFilterProject` is a helper method used exclusively in link:spark-sql-SparkStrategy-InMemoryScans.adoc[InMemoryScans] and `HiveTableScans` execution planning strategies.
