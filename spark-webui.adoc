== WebUI -- Spark Application's Web Console

*Web UI* (aka *webUI* or *Spark UI* after <<SparkUI, SparkUI>>) is the web interface of a running Spark application to monitor and inspect Spark job executions in a browser.

.Welcome page - Jobs page
image::images/spark-webui-jobs.png[align="center"]

Every `SparkContext` link:spark-sparkcontext-creating-instance-internals.adoc[launches its own instance of Web UI] which is available at `http://[master]:4040` by default (the port can be changed using <<spark_ui_port, spark.ui.port>> setting) and will increase if this port is already taken (until an open port is found).

web UI comes with the following tabs (which may not all be visible at once as they are lazily created on demand, e.g. the link:spark-webui-sql.adoc[SQL] and Streaming tabs):

1. link:spark-webui-jobs.adoc[Jobs]
2. link:spark-webui-stages.adoc[Stages]
3. link:spark-webui-storage.adoc[Storage] with RDD size and memory use
4. <<environment-tab, Environment>>
5. link:spark-webui-executors.adoc[Executors]
6. link:spark-webui-sql.adoc[SQL]

TIP: You can use the web UI after the application has finished by link:spark-scheduler-listeners-eventlogginglistener.adoc[persisting events using EventLoggingListener].

NOTE: All the information that are displayed in web UI is available thanks to link:spark-webui-JobProgressListener.adoc[JobProgressListener]. One could say that web UI is a web layer to `JobProgressListener`.

=== [[environment-tab]] Environment Tab

.Environment tab in Web UI
image::images/spark-webui-environment.png[align="center"]

=== [[SparkUI]] SparkUI

`SparkUI` is...FIXME

==== [[SparkUI-createLiveUI]] createLiveUI

CAUTION: FIXME

==== [[SparkUI-appUIAddress]] appUIAddress

CAUTION: FIXME

=== [[settings]] Settings

==== [[spark_ui_enabled]] spark.ui.enabled

`spark.ui.enabled` (default: `true`) setting controls whether the web UI is started at all.

==== [[spark_ui_port]] spark.ui.port

`spark.ui.port` (default: `4040`) controls the port Web UI binds to.

If multiple SparkContexts attempt to run on the same host (it is not possible to have two or more Spark contexts on a single JVM, though), they will bind to successive ports beginning with `spark.ui.port`.

==== [[spark_ui_killEnabled]] spark.ui.killEnabled

`spark.ui.killEnabled` (default: `true`) - whether or not you can kill stages in web UI.
