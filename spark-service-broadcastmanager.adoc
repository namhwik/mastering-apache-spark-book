== Broadcast Manager

*Broadcast Manager* is a Spark service to manage broadcast values in Spark jobs. It is created for a Spark application as part of link:spark-sparkcontext.adoc#creating-instance[SparkContext's initialization] and is a simple wrapper around <<BroadcastFactory, BroadcastFactory>>.

Broadcast Manager tracks the number of broadcast values (using the internal field `nextBroadcastId`).

The idea is to transfer values used in transformations from a driver to executors in a most effective way so they are copied once and used many times by tasks (rather than being copied every time a task is launched).

When `BroadcastManager` is initialized an instance of `BroadcastFactory` is created based on <<settings, spark.broadcast.factory>> setting.

=== [[BroadcastFactory]] BroadcastFactory

`BroadcastFactory` is a pluggable interface for broadcast implementations in Spark. It is exclusively used and instantiated inside of `BroadcastManager` to manage broadcast variables.

It comes with 4 methods:

* `def initialize(isDriver: Boolean, conf: SparkConf, securityMgr: SecurityManager): Unit`
* `def newBroadcast[T: ClassTag](value: T, isLocal: Boolean, id: Long): Broadcast[T]` - called after `SparkContext.broadcast()` has been called.
* `def unbroadcast(id: Long, removeFromDriver: Boolean, blocking: Boolean): Unit`
* `def stop(): Unit`

=== [[compression]] Compression

With <<settings, spark.broadcast.compress>> enabled (which is the default), link:spark-broadcast.adoc#TorrentBroadcast[TorrentBroadcast] does compression.

CAUTION: FIXME What's compressed?

.Built-in Compression Codecs
[width="100%",cols="1,1,3",frame="topbot",options="header,footer"]
|======================
|Alias | Fully-Qualified Class Name | Notes
| `lz4` | `org.apache.spark.io.LZ4CompressionCodec` | The default implementation
| `snappy` | `org.apache.spark.io.SnappyCompressionCodec` | The fallback when the default codec is not available.
| `lzf` | `org.apache.spark.io.LZFCompressionCodec` |
|======================

An implementation of `CompressionCodec` trait has to offer a constructor that accepts link:spark-configuration.adoc[SparkConf].

Internally, `TorrentBroadcast` sets the internal `compressionCodec` value that is later used to create blocks for an object (in `TorrentBroadcast.blockifyObject`) and to create the object out of the blocks (in `TorrentBroadcast.unBlockifyObject`).

CAUTION: FIXME Review `TorrentBroadcast.blockifyObject` and `TorrentBroadcast.unBlockifyObject`.

=== [[settings]] Settings

.Settings
[width="100%",cols="1,1,3",frame="topbot",options="header,footer"]
|======================
|Name | Default value |Description
| `spark.broadcast.factory` | `org.apache.spark.broadcast.TorrentBroadcastFactory` | The fully-qualified class name for the implementation of `BroadcastFactory` interface.
| `spark.broadcast.compress` | `true` | The flag to enable compression. See <<compression, Compression>> in this document.

The setting is also used in link:spark-SerializerManager.adoc#settings[SerializerManager].

| `spark.broadcast.blockSize` | `4m` | The size of a block
| [[spark.io.compression.codec]] `spark.io.compression.codec` | `lz4` | The compression codec to use. See <<compression, Compression>>.
|======================
