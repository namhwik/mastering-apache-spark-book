== [[ExecutorsListener]] `ExecutorsListener` Spark Listener

`ExecutorsListener` is a  link:spark-SparkListener.adoc[SparkListener] that tracks <<registries, executors and their tasks>> in a Spark application for link:spark-webui-StagePage.adoc[Stage Details] page, link:spark-webui-jobs.adoc[Jobs] tab and `/allexecutors` REST endpoint.

.`ExecutorsListener` Event Handlers
[cols="1,2",options="header",width="100%"]
|===
| Event Handler | Description

| <<onApplicationStart, onApplicationStart>> | May create an entry for the driver in <<executorToTaskSummary, executorToTaskSummary>> registry

| <<onExecutorAdded, onExecutorAdded>> | May create an entry in <<executorToTaskSummary, executorToTaskSummary>> registry. It also makes sure that the number of entries for dead executors does not exceed link:spark-webui.adoc#spark_ui_retainedDeadExecutors[spark.ui.retainedDeadExecutors] and removes excess.

Adds an entry to <<executorEvents, executorEvents>> registry and optionally removes the oldest if the number of entries exceeds <<spark_ui_timeline_executors_maximum, spark.ui.timeline.executors.maximum>>.

| <<onExecutorRemoved, onExecutorRemoved>> | Marks an executor dead in <<executorToTaskSummary, executorToTaskSummary>> registry.

Adds an entry to <<executorEvents, executorEvents>> registry and optionally removes the oldest if the number of entries exceeds <<spark_ui_timeline_executors_maximum, spark.ui.timeline.executors.maximum>>.

| <<onTaskStart, onTaskStart>> | May create an entry for an executor in <<executorToTaskSummary, executorToTaskSummary>> registry.

| <<onTaskEnd, onTaskEnd>> | May create an entry for an executor in <<executorToTaskSummary, executorToTaskSummary>> registry.
|===

`ExecutorsListener` requires a link:spark-webui-StorageStatusListener.adoc[StorageStatusListener] and link:spark-configuration.adoc[SparkConf].

=== [[registries]] Registries

.`ExecutorsListener` Registries
[cols="1,2",options="header",width="100%"]
|===
| Registry | Description
| [[executorToTaskSummary]] `executorToTaskSummary` | The lookup table for `ExecutorTaskSummary` per executor id.

Used to build a `ExecutorSummary` for `/allexecutors` REST endpoint, to display stdout and stderr logs in link:spark-webui-StagePage.adoc#tasks[Tasks] and link:spark-webui-StagePage.adoc#aggregated-metrics-by-executor[Aggregated Metrics by Executor] sections in link:spark-webui-StagePage.adoc[Stage Details] page.

| [[executorEvents]] `executorEvents` | A collection of link:spark-SparkListener.adoc#SparkListenerEvent[SparkListenerEvent]s.

Used to build the event timeline in link:spark-webui-jobs.adoc#AllJobsPage[All Jobs] and link:spark-webui-jobs.adoc#JobPage[Details for Job] pages.
|===

=== [[onApplicationStart]] `onApplicationStart` Method

[source, scala]
----
onApplicationStart(applicationStart: SparkListenerApplicationStart): Unit
----

`onApplicationStart` takes `driverLogs` property from the input `applicationStart` (if defined) and finds the driver's active `StorageStatus` (using the current link:spark-webui-StorageStatusListener.adoc[StorageStatusListener]). `onApplicationStart` then uses the driver's `StorageStatus` (if defined) to set `executorLogs`.

.ExecutorTaskSummary and ExecutorInfo Attributes
[options="header",width="100%"]
|===
| ExecutorTaskSummary Attribute | SparkListenerApplicationStart Attribute
| `executorLogs` | `driverLogs` (if defined)
|===

=== [[onExecutorAdded]] `onExecutorAdded` Method

[source, scala]
----
onExecutorAdded(executorAdded: SparkListenerExecutorAdded): Unit
----

`onExecutorAdded` finds the executor (using the input `executorAdded`) in the internal <<executorToTaskSummary, `executorToTaskSummary` registry>> and sets the attributes. If not found, `onExecutorAdded` creates a new entry.

.ExecutorTaskSummary and ExecutorInfo Attributes
[options="header",width="100%"]
|===
| ExecutorTaskSummary Attribute | ExecutorInfo Attribute
| `executorLogs` | `logUrlMap`
| `totalCores` | `totalCores`
| `tasksMax` | `totalCores` / link:spark-taskschedulerimpl.adoc#spark.task.cpus[spark.task.cpus]
|===

`onExecutorAdded` adds the input `executorAdded` to <<executorEvents, `executorEvents` collection>>. If the number of elements in `executorEvents` collection is greater than <<spark_ui_timeline_executors_maximum, spark.ui.timeline.executors.maximum>>, the first/oldest event is removed.

`onExecutorAdded` removes the oldest dead executor from <<executorToTaskSummary, `executorToTaskSummary` lookup table>> if their number is greater than link:spark-webui.adoc#spark_ui_retainedDeadExecutors[spark.ui.retainedDeadExecutors].

=== [[onExecutorRemoved]] `onExecutorRemoved` Method

[source, scala]
----
onExecutorRemoved(executorRemoved: SparkListenerExecutorRemoved): Unit
----

`onExecutorRemoved` adds the input `executorRemoved` to <<executorEvents, `executorEvents` collection>>. It then removes the oldest event if the number of elements in `executorEvents` collection is greater than <<spark_ui_timeline_executors_maximum, spark.ui.timeline.executors.maximum>>.

The executor is marked as removed/inactive in <<executorToTaskSummary, `executorToTaskSummary` lookup table>>.

=== [[onTaskStart]] `onTaskStart` Method

[source, scala]
----
onTaskStart(taskStart: SparkListenerTaskStart): Unit
----

`onTaskStart` increments `tasksActive` for the executor (using the input `SparkListenerTaskStart`).

.ExecutorTaskSummary and SparkListenerTaskStart Attributes
[options="header",width="100%"]
|===
| ExecutorTaskSummary Attribute | Description
| `tasksActive` | Uses `taskStart.taskInfo.executorId`.
|===

=== [[onTaskEnd]] Intercepting Task End Events -- `onTaskEnd` Callback

[source, scala]
----
onTaskEnd(taskEnd: SparkListenerTaskEnd): Unit
----

`onTaskEnd` takes link:spark-TaskInfo.adoc[TaskInfo] from the input `taskEnd` (if available).

Depending on the reason for `SparkListenerTaskEnd` `onTaskEnd` does the following:

.`onTaskEnd` Behaviour per `SparkListenerTaskEnd` Reason
[cols="1,2",options="header",width="100%"]
|===
| `SparkListenerTaskEnd` Reason | `onTaskEnd` Behaviour
| `Resubmitted` | Does nothing
| `ExceptionFailure` | Increment `tasksFailed`
| _anything_ | Increment `tasksComplete`
|===

`tasksActive` is decremented but only when the number of active tasks for the executor is greater than `0`.

.ExecutorTaskSummary and `onTaskEnd` Behaviour
[options="header",width="100%"]
|===
| ExecutorTaskSummary Attribute | Description
| `tasksActive` | Decremented if greater than 0.
| `duration` | Uses `taskEnd.taskInfo.duration`
|===

If the `TaskMetrics` (in the input `taskEnd`) is available, the metrics are added to the `taskSummary` for the task's executor.

.Task Metrics and Task Summary
[cols="1,2",options="header",width="100%"]
|===
| Task Summary | Task Metric
| `inputBytes` | `inputMetrics.bytesRead`
| `inputRecords` | `inputMetrics.recordsRead`
| `outputBytes` | `outputMetrics.bytesWritten`
| `outputRecords` | `outputMetrics.recordsWritten`
| `shuffleRead` | `shuffleReadMetrics.remoteBytesRead`
| `shuffleWrite` | link:spark-taskmetrics-ShuffleWriteMetrics.adoc#bytesWritten[shuffleWriteMetrics.bytesWritten]
| `jvmGCTime` | `metrics.jvmGCTime`
|===

=== [[settings]] Settings

.`ExecutorsListener` Spark Properties
[cols="1,1,2",options="header",width="100%"]
|===
| Name | Default Value | Description
| [[spark_ui_timeline_executors_maximum]] `spark.ui.timeline.executors.maximum` | `1000` | The maximum number of entries in <<executorEvents, executorEvents>> registry.
|===
