== MapOutputTracker

A *MapOutputTracker* is a Spark service to track the locations of the (shuffle) map outputs of a stage. It uses an internal MapStatus map with an array of `MapStatus` for every partition for a shuffle id.

There are two versions of `MapOutputTracker`:

* link:spark-service-MapOutputTrackerMaster.adoc[MapOutputTrackerMaster] for a driver
* <<MapOutputTrackerWorker, MapOutputTrackerWorker>> for executors

MapOutputTracker is available under `SparkEnv.get.mapOutputTracker`. It is also available as `MapOutputTracker` in the driver's RPC Environment.

[TIP]
====
Enable `DEBUG` logging level for `org.apache.spark.MapOutputTracker` logger to see what happens in MapOutputTracker.

Add the following line to `conf/log4j.properties`:

```
log4j.logger.org.apache.spark.MapOutputTracker=DEBUG
```
====

It works with link:spark-rdd-shuffledrdd.adoc[ShuffledRDD] when it asks for *preferred locations for a shuffle* using `tracker.getPreferredLocationsForShuffle`.

It is also used for `mapOutputTracker.containsShuffle` and link:spark-service-MapOutputTrackerMaster.adoc#registerShuffle[MapOutputTrackerMaster.registerShuffle] when a new link:spark-dagscheduler-ShuffleMapStage.adoc[ShuffleMapStage] is created.

CAUTION: FIXME `DAGScheduler.mapOutputTracker`

link:spark-service-MapOutputTrackerMaster.adoc#getStatistics[MapOutputTrackerMaster.getStatistics(dependency)] returns `MapOutputStatistics` that becomes the result of link:spark-dagscheduler-JobListener.adoc#JobWaiter[JobWaiter.taskSucceeded] for link:spark-dagscheduler-ShuffleMapStage.adoc[ShuffleMapStage] if it's the final stage in a job.

link:spark-service-MapOutputTrackerMaster.adoc#registerMapOutputs[MapOutputTrackerMaster.registerMapOutputs] for a shuffle id and a list of `MapStatus` when a link:spark-dagscheduler-ShuffleMapStage.adoc[ShuffleMapStage] is finished.

=== [[unregisterShuffle]] unregisterShuffle

CAUTION: FIXME

=== [[MapStatus]] MapStatus

A *MapStatus* is the result returned by a <<spark-taskscheduler.adoc#shufflemaptask, ShuffleMapTask>> to link:spark-dagscheduler.adoc[DAGScheduler] that includes:

* the *location* where ShuffleMapTask ran (as `def location: BlockManagerId`)
* an *estimated size for the reduce block*, in bytes (as `def getSizeForBlock(reduceId: Int): Long`).

There are two types of MapStatus:

* *CompressedMapStatus* that compresses the estimated map output size to 8 bits (`Byte`) for efficient reporting.
* *HighlyCompressedMapStatus* that stores the average size of non-empty blocks, and a compressed bitmap for tracking which blocks are empty.

When the number of blocks (the size of `uncompressedSizes`) is greater than *2000*, HighlyCompressedMapStatus is chosen.

CAUTION: FIXME What exactly is 2000? Is this the number of tasks in a job?

CAUTION: FIXME Review ShuffleManager

=== [[epoch]] Epoch Number

CAUTION: FIXME

=== [[MapOutputTrackerWorker]] MapOutputTrackerWorker

A *MapOutputTrackerWorker* is the `MapOutputTracker` for executors. The internal `mapStatuses` map serves as a cache and any miss triggers a fetch from the driver's link:spark-service-MapOutputTrackerMaster.adoc[MapOutputTrackerMaster].

NOTE: The only difference between `MapOutputTrackerWorker` and the base abstract class `MapOutputTracker` is that the internal `mapStatuses` mapping between ints and an array of `MapStatus` objects is an instance of the thread-safe https://docs.oracle.com/javase/8/docs/api/java/util/concurrent/ConcurrentHashMap.html[java.util.concurrent.ConcurrentHashMap].
