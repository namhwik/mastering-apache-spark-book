== Spark local (pseudo-cluster)

You can run Spark in *local mode*. In this non-distributed single-JVM deployment mode, Spark spawns all the execution components - link:spark-driver.adoc[driver], link:spark-executor.adoc[executor], <<LocalBackend, backend>>, and link:spark-master.adoc[master] - in the same single JVM. The default parallelism is the number of threads as specified in the <<masterURL, master URL>>. This is the only mode where a driver is used for execution.

.Architecture of Spark local
image::diagrams/spark-local-architecture.png[align="center"]

The local mode is very convenient for testing, debugging or demonstration purposes as it requires no earlier setup to launch Spark applications.

This mode of operation is also called  http://spark.apache.org/docs/latest/programming-guide.html#initializing-spark[Spark in-process] or (less commonly) *a local version of Spark*.

`SparkContext.isLocal` returns `true` when Spark runs in local mode.

```
scala> sc.isLocal
res0: Boolean = true
```

link:spark-shell.adoc[Spark shell] defaults to local mode with `local[*]` as the link:spark-deployment-environments.adoc#master-urls[the master URL].

```
scala> sc.master
res0: String = local[*]
```

Tasks are not re-executed on failure in local mode (unless <<masterURL, local-with-retries master URL>> is used).

The link:spark-taskscheduler.adoc[task scheduler] in local mode works with <<LocalBackend, LocalBackend>> task scheduler backend.

=== [[masterURL]] Master URL

You can run Spark in local mode using `local`, `local[n]` or the most general `local[*]` for link:spark-deployment-environments.adoc#master-urls[the master URL].

The URL says how many threads can be used in total:

* `local` uses 1 thread only.

* `local[n]` uses `n` threads.

* `local[*]` uses as many threads as the number of processors available to the Java virtual machine (it uses https://docs.oracle.com/javase/8/docs/api/java/lang/Runtime.html#availableProcessors--[Runtime.getRuntime.availableProcessors()] to know the number).

CAUTION: FIXME What happens when there's less cores than `n` in the master URL? It is a question from twitter.

* `local[N, M]` (called *local-with-retries*) with `N` being `*` or the number of threads to use (as explained above) and `M` being the value of link:spark-taskscheduler.adoc#spark_task_maxFailures[spark.task.maxFailures].

=== [[task-submission]] Task Submission a.k.a. reviveOffers

.TaskSchedulerImpl.submitTasks in local mode
image::images/taskscheduler-submitTasks-local-mode.png[align="center"]

When `ReviveOffers` or `StatusUpdate` messages are received, `LocalEndpoint` places an offer to `TaskSchedulerImpl` (using `TaskSchedulerImpl.resourceOffers`).

If there is one or more tasks that match the offer, they are launched (using `executor.launchTask` method).

The number of tasks to be launched is controlled by the number of threads as specified in <<masterURL, master URL>>. The executor uses threads to spawn the tasks.

=== [[LocalBackend]] LocalBackend

`LocalBackend` is a link:spark-scheduler-backends.adoc[scheduler backend] and a link:spark-executor-backends.adoc[executor backend] for Spark local mode.

It acts as a "cluster manager" for local mode to offer resources on the single link:spark-workers.adoc[worker] it manages, i.e. it calls `TaskSchedulerImpl.resourceOffers(offers)` with `offers` being a single-element collection with `WorkerOffer("driver", "localhost", freeCores)`.

CAUTION: FIXME Review `freeCores`. It appears you could have many jobs running simultaneously.

When an executor sends task status updates (using `ExecutorBackend.statusUpdate`), they are passed along as <<messages, StatusUpdate>> to <<LocalEndpoint, LocalEndpoint>>.

.Task status updates flow in local mode
image::images/LocalBackend-LocalEndpoint-Executor-task-status-updates.png[align="center"]

When LocalBackend starts up, it registers a new link:spark-rpc.adoc#rpcendpoint[RPC Endpoint] called *LocalBackendEndpoint* that is backed by <<LocalEndpoint, LocalEndpoint>>. This is announced on link:spark-LiveListenerBus.adoc[LiveListenerBus] as `driver` (using link:spark-SparkListener.adoc#SparkListenerExecutorAdded[SparkListenerExecutorAdded] message).

The application ids are in the format of `local-[current time millis]`.

It communicates with <<LocalEndpoint, LocalEndpoint>> using <<messages, RPC messages>>.

The default parallelism is controlled using link:spark-rdd-partitions.adoc#spark_default_parallelism[spark.default.parallelism] property.

=== [[LocalEndpoint]] LocalEndpoint

*LocalEndpoint* is the communication channel between link:spark-taskscheduler.adoc[Task Scheduler] and <<LocalBackend, LocalBackend>>. It is a (thread-safe) link:spark-rpc.adoc#rpcendpoint[RPC Endpoint] that hosts an link:spark-executor.adoc[executor] (with id `driver` and hostname `localhost`) for Spark local mode.

When a `LocalEndpoint` starts up (as part of Spark local's initialization) it prints out the following INFO messages to the logs:

```
INFO Executor: Starting executor ID driver on host localhost
INFO Executor: Using REPL class URI: http://192.168.1.4:56131
```

==== [[LocalEndpoint-creating-instance]] Creating LocalEndpoint Instance

CAUTION: FIXME

==== [[messages]] RPC Messages

LocalEndpoint accepts the following RPC message types:

* `ReviveOffers` (receive-only, non-blocking) - read <<task-submission, Task Submission a.k.a. reviveOffers>>.

* `StatusUpdate` (receive-only, non-blocking) that passes the message to TaskScheduler (using `statusUpdate`) and if link:spark-taskscheduler-tasks.adoc[the task's status is finished], it revives offers (see `ReviveOffers`).

* `KillTask` (receive-only, non-blocking) that kills the task that is currently running on the executor.

* `StopExecutor` (receive-reply, blocking) that stops the executor.
