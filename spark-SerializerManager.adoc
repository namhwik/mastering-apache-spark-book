== SerializerManager

CAUTION: FIXME

When link:spark-sparkenv.adoc#create[`SparkEnv` is created] (either for the driver or executors), it instantiates `SerializerManager` that is then used to create a link:spark-blockmanager.adoc[BlockManager].

It automatically selects the best serializer which is `KryoSerializer` <<canUseKryo, whenever possible>> or falls backs to the input `defaultSerializer` serializer.

The common idiom in Spark's code is to access the current `SerializerManager` using link:spark-sparkenv.adoc#get[SparkEnv.get].

[source, scala]
----
SparkEnv.get.serializerManager
----

=== [[canUseKryo]][[selecting-serializer]] Automatic Selection of Best Serializer

CAUTION: FIXME

=== [[settings]] Settings

.Settings
[width="100%",cols="1,1,3",frame="topbot",options="header,footer"]
|======================
|Name | Default value |Description
| `spark.broadcast.compress` | `true` | The flag to control whether to compress broadcast variables when stored.

The setting is also used in link:spark-broadcast.adoc#TorrentBroadcast[TorrentBroadcast].
| `spark.shuffle.compress` | `true` | The flag to control whether to compress shuffle output when stored
| `spark.rdd.compress` | `false` | The flag to control whether to compress RDD partitions when stored serialized.
| `spark.shuffle.spill.compress` | `true` | The flag to control whether to compress shuffle output temporarily spilled to disk.
| [[spark.block.failures.beforeLocationRefresh]] `spark.block.failures.beforeLocationRefresh` | `5` |
| [[spark.io.encryption.enabled]] `spark.io.encryption.enabled` | `false` | The flag to enable IO encryption
|======================
