== ExecutorAllocationClient

`ExecutorAllocationClient` is a contract for clients to communicate with a cluster manager to request or kill executors.

=== [[getExecutorIds]] Getting Executor Ids (getExecutorIds method)

[source, scala]
----
getExecutorIds(): Seq[String]
----

`getExecutorIds` is a `private[spark]` method to calculate the identifiers of the executors in use.

NOTE: It is used when link:spark-sparkcontext.adoc#getExecutorIds[`SparkContext` calculates the executors in use] and also when link:spark-streaming/spark-streaming-dynamic-allocation.adoc[Spark Streaming manages executors].

=== [[requestTotalExecutors]] Requesting Exact Number of Executors (requestTotalExecutors method)

[source, scala]
----
requestTotalExecutors(
  numExecutors: Int,
  localityAwareTasks: Int,
  hostToLocalTaskCount: Map[String, Int]): Boolean
----

`requestTotalExecutors` is a `private[spark]` method to update the cluster manager with the exact number of executors desired. It returns whether the request has been acknowledged by the cluster manager (`true`) or not (`false`).

[NOTE]
====
It is used when:

1. link:spark-sparkcontext.adoc#requestTotalExecutors[`SparkContext` requests executors] (for coarse-grained scheduler backends only).

2. `ExecutorAllocationManager` link:spark-service-executor-allocation-manager.adoc#start[starts], does link:spark-service-executor-allocation-manager.adoc#updateAndSyncNumExecutorsTarget[updateAndSyncNumExecutorsTarget], and link:spark-service-executor-allocation-manager.adoc#addExecutors[addExecutors].

3. Streaming `ExecutorAllocationManager` link:spark-streaming/spark-streaming-ExecutorAllocationManager.adoc#requestExecutors[requests executors].

4. link:yarn/spark-yarn-yarnschedulerbackend.adoc#stop[`YarnSchedulerBackend` stops].
====

=== [[requestExecutors]] Requesting Additional Executors (requestExecutors method)

[source, scala]
----
requestExecutors(numAdditionalExecutors: Int): Boolean
----

`requestExecutors` requests additional executors from a cluster manager and returns whether the request has been acknowledged by the cluster manager (`true`) or not (`false`).

NOTE: It is used when link:spark-sparkcontext.adoc#requestExecutors[`SparkContext` requests additional executors] (for coarse-grained scheduler backends only).

=== [[killExecutors]] Requesting to Kill Single Executor (killExecutor method)

[source, scala]
----
killExecutor(executorId: String): Boolean
----

`killExecutor` requests that a cluster manager to kill a single executor that is no longer in use and returns whether the request has been acknowledged by the cluster manager (`true`) or not (`false`).

NOTE: The default implementation simply calls <<killExecutors, killExecutors>> (with a single-element collection of executors to kill).

[NOTE]
====
It is used in:

1. `ExecutorAllocationManager` to link:spark-service-executor-allocation-manager.adoc#removeExecutor[remove executor].

2. `SparkContext` to link:spark-sparkcontext.adoc#killExecutors[request to kill executors].

3. Streaming `ExecutorAllocationManager` to link:spark-streaming/spark-streaming-ExecutorAllocationManager.adoc#killExecutor[request to kill executors].
====

=== [[killExecutors]] Requesting to Kill Executors (killExecutors method)

[source, scala]
----
killExecutors(executorIds: Seq[String]): Boolean
----

`killExecutors` requests that a cluster manager to kill one or many executors that are no longer in use and returns whether the request has been acknowledged by the cluster manager (`true`) or not (`false`).

NOTE: _Interestingly_, it is only used for <<killExecutor, killExecutor>>.
