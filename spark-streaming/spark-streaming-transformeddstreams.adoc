== TransformedDStream

`TransformedDStream` is the specialized link:spark-streaming-dstreams.adoc[DStream] that is the result of link:spark-streaming-operators.adoc#transform[transform] operator.

It is constructed with a collection of `parents` dstreams and `transformFunc` transform function.

NOTE: When created, it asserts that the input collection of dstreams use the same StreamingContext and slide interval.

NOTE: It is acceptable to have more than one dependent dstream.

The link:spark-streaming-dstreams.adoc#contract[dependencies] is the input collection of dstreams.

The link:spark-streaming-dstreams.adoc#contract[slide interval] is exactly the same as that in the first dstream in `parents`.

When requested to link:spark-streaming-dstreams.adoc#contract[compute a RDD], it goes over every dstream in `parents` and asks to getOrCompute a RDD.

NOTE: It may throw a `SparkException` when a dstream does not compute a RDD for a batch.

CAUTION: FIXME Prepare an example to face the exception.

It then calls `transformFunc` with the collection of RDDs.

If the transform function returns `null` a SparkException is thrown:

[options="wrap"]
----
org.apache.spark.SparkException: Transform function must not return null. Return SparkContext.emptyRDD() instead to represent no element as the result of transformation.
	at org.apache.spark.streaming.dstream.TransformedDStream.compute(TransformedDStream.scala:48)
----

The result of `transformFunc` is returned.
