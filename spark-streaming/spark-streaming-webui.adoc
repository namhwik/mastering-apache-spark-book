== web UI and Streaming Statistics Page

When you link:spark-streaming-streamingcontext.adoc#start[start a Spark Streaming application], you can use link:../spark-webui.adoc[web UI] to monitor streaming statistics in *Streaming* tab (aka _page_).

.Streaming Tab in web UI
image::../images/spark-streaming-webui-streaming-tab.png[align="center"]

NOTE: The number of completed batches to retain to compute statistics upon is controlled by link:spark-streaming-settings.adoc[spark.streaming.ui.retainedBatches] (and defaults to `1000`).

The page is made up of three sections (aka _tables_) - the unnamed, top-level one with <<basic-info, basic information>> about the streaming application (right below the title *Streaming Statistics*), <<active-batches, Active Batches>> and <<catched-batches, Completed Batches>>.

NOTE: The Streaming page uses link:spark-streaming-streaminglisteners.adoc#StreamingJobProgressListener[StreamingJobProgressListener] for most of the information displayed.

=== [[basic-info]] Basic Information

*Basic Information* section is the top-level section in the Streaming page that offers basic information about the streaming application.

.Basic Information section in Streaming Page (with Receivers)
image::../images/spark-streaming-webui-streaming-statistics.png[align="center"]

The section shows the link:spark-streaming-dstreamgraph.adoc#batchDuration[batch duration] (in _Running batches of [batch duration]_), and the time it runs for and since link:spark-streaming-streamingcontext.adoc#creating-instance[StreamingContext was created] (_not_ when this streaming application has been started!).

It shows the number of all *completed batches* (for the entire period since the StreamingContext was started) and *received records* (in parenthesis). These information are later displayed in detail in <<active-batches, Active Batches>> and <<catched-batches, Completed Batches>> sections.

Below is the table for link:spark-streaming-streaminglisteners.adoc#retainedBatches[retained batches] (i.e. waiting, running, and completed batches).

In *Input Rate* row, you can show and hide details of each input stream.

If there are link:spark-streaming-receiverinputdstreams.adoc[input streams with receivers], the numbers of all the receivers and active ones are displayed (as depicted in the Figure 2 above).

The average event rate for all registered streams is displayed (as _Avg: [avg] events/sec_).

==== [[scheduling-delay]] Scheduling Delay

*Scheduling Delay* is the time spent from link:spark-streaming-jobscheduler.adoc#submitJobSet[when the collection of streaming jobs for a batch was submitted] to link:spark-streaming-jobscheduler.adoc#JobStarted[when the first streaming job (out of possibly many streaming jobs in the collection) was started].

.Scheduling Delay in Streaming Page
image::../images/spark-streaming-webui-streaming-page-scheduling-delay.png[align="center"]

It should be as low as possible meaning that the streaming jobs in batches are scheduled almost instantly.

NOTE: The values in the timeline (the first column) depict the time between the events link:spark-streaming-streaminglisteners.adoc#StreamingListenerEvent[StreamingListenerBatchSubmitted] and link:spark-streaming-streaminglisteners.adoc#StreamingListenerEvent[StreamingListenerBatchStarted] (with minor yet additional delays to deliver the events).

You may see increase in scheduling delay in the timeline when streaming jobs are queued up as in the following example:

[source, scala]
----
// batch duration = 5 seconds
val messages: InputDStream[(String, String)] = ...
messages.foreachRDD { rdd =>
  println(">>> Taking a 15-second sleep")
  rdd.foreach(println)
  java.util.concurrent.TimeUnit.SECONDS.sleep(15)
}
----

.Scheduling Delay Increased in Streaming Page
image::../images/spark-streaming-webui-scheduling-delay-increase.png[align="center"]

==== [[processing-time]] Processing Time

*Processing Time* is the time spent to complete all the streaming jobs of a batch.

.Batch Processing Time and Batch Intervals
image::../images/spark-streaming-batch-processing-time.png[align="center"]

==== [[total-delay]] Total Delay

*Total Delay* is the time spent from submitting to complete all jobs of a batch.

=== [[active-batches]] Active Batches

*Active Batches* section presents `waitingBatches` and `runningBatches` together.

=== [[completed-batches]] Completed Batches

*Completed Batches* section presents retained completed batches (using `completedBatchUIData`).

NOTE: The number of retained batches is controlled by link:spark-streaming-settings.adoc[spark.streaming.ui.retainedBatches].

.Completed Batches (limited to 5 elements only)
image::../images/spark-streaming-webui-completed-batches.png[align="center"]

=== Example - Kafka Direct Stream in web UI

.Two Batches with Incoming Data inside for Kafka Direct Stream in web UI (Streaming tab)
image::../images/spark-streaming-webui-streaming-tab-kafka-directstream-two-batches.png[align="center"]

.Two Jobs for Kafka Direct Stream in web UI (Jobs tab)
image::../images/spark-streaming-webui-kafka-directinputstream-two-jobs.png[align="center"]
