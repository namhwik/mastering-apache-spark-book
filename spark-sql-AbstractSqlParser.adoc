== [[AbstractSqlParser]] AbstractSqlParser -- Base SQL Parsing Infrastructure

`AbstractSqlParser` is the one and only link:spark-sql-ParserInterface.adoc[ParserInterface] in Spark SQL that acts as the foundation of the SQL parsing infrastructure with <<implementations, two concrete implementations available>> (that are _merely_ required to define their custom <<astBuilder, AstBuilder>> for the final transformation of SQL textual representation to their Spark SQL equivalent entities, i.e. link:spark-sql-DataType.adoc[DataType], link:spark-sql-Expression.adoc[Expression], link:spark-sql-LogicalPlan.adoc[LogicalPlan] and `TableIdentifier`).

`AbstractSqlParser` first <<parse, sets up `SqlBaseLexer` and `SqlBaseParser` for parsing>> (and pass the latter on to a parsing function) and use <<astBuilder, `AstBuilder` for the actual parsing>>.

[[implementations]]
.AbstractSqlParser's Implementations (in alphabetical order)
[width="100%",cols="1,2",options="header"]
|===
| Name
| Description

| link:spark-sql-SparkSqlParser.adoc[SparkSqlParser]
a| The default SQL parser available as `sqlParser` in link:spark-sql-SessionState.adoc#sqlParser[SessionState].

[source, scala]
----
val spark: SparkSession = ...
spark.sessionState.sqlParser
----

| link:spark-sql-CatalystSqlParser.adoc[CatalystSqlParser]
| Parses link:spark-sql-DataType.adoc[DataType] or link:spark-sql-StructType.adoc[StructType] (schema) from their canonical string representation.
|===

`AbstractSqlParser` simply relays all the SQL parsing to translate a SQL string to that specialized <<astBuilder, AstBuilder>>.

=== [[contract]] AbstractSqlParser Contract

[source, scala]
----
abstract class AbstractSqlParser extends ParserInterface {
  def astBuilder: AstBuilder
  def parse[T](command: String)(toResult: SqlBaseParser => T): T
  def parseDataType(sqlText: String): DataType
  def parsePlan(sqlText: String): LogicalPlan
  def parseExpression(sqlText: String): Expression
  def parseTableIdentifier(sqlText: String): TableIdentifier
  def parseTableSchema(sqlText: String): StructType
}
----

.AbstractSqlParser Contract (in alphabetical order)
[cols="1,2",options="header",width="100%"]
|===
| Method
| Description

| [[astBuilder]] `astBuilder`
a| Gives link:spark-sql-AstBuilder.adoc[AstBuilder] for the actual SQL parsing.

Used in all the `parse` methods, i.e. <<parseDataType, parseDataType>>, <<parseExpression, parseExpression>>, <<parsePlan, parsePlan>>, <<parseTableIdentifier, parseTableIdentifier>>, and <<parseTableSchema, parseTableSchema>>.

NOTE: Both <<implementations, implementations>>, i.e. link:spark-sql-SparkSqlParser.adoc[SparkSqlParser] and link:spark-sql-CatalystSqlParser.adoc[CatalystSqlParser], come with their own `astBuilder` method.

| <<parse, parse>>
| Sets up `SqlBaseLexer` and `SqlBaseParser` for parsing and passes the latter on to the input `toResult` function where the parsing finally happens.

Used in all the `parse` methods, i.e. <<parseDataType, parseDataType>>, <<parseExpression, parseExpression>>, <<parsePlan, parsePlan>>, <<parseTableIdentifier, parseTableIdentifier>>, and <<parseTableSchema, parseTableSchema>>.

| [[parseDataType]] `parseDataType`
| Used when...

| [[parseExpression]] `parseExpression`
| Used when...

| [[parsePlan]] `parsePlan`
a| Creates a link:spark-sql-LogicalPlan.adoc[LogicalPlan] for a given SQL textual statement.

`parsePlan` <<parse, builds a `SqlBaseParser`>> and requests <<astBuilder, AstBuilder>> to link:spark-sql-AstBuilder.adoc#visitSingleStatement[parse a single SQL statement].

When a SQL statement could not be parsed, `parsePlan` reports a `ParseException`:

```
Unsupported SQL statement
```

| [[parseTableIdentifier]] `parseTableIdentifier`
| Used when...

| [[parseTableSchema]] `parseTableSchema`
| Used when...
|===

=== [[parse]] Setting Up SqlBaseLexer and SqlBaseParser for Parsing -- `parse` Method

[source, scala]
----
parse[T](command: String)(toResult: SqlBaseParser => T): T
----

`parse` sets up a proper ANTLR parsing infrastructure with `SqlBaseLexer` and `SqlBaseParser` (which are the ANTLR-specific classes of Spark SQL that are auto-generated at build time from the `SqlBase.g4` grammar).

TIP: Review the definition of ANTLR grammar for Spark SQL in https://github.com/apache/spark/blob/master/sql/catalyst/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBase.g4[sql/catalyst/src/main/antlr4/org/apache/spark/sql/catalyst/parser/SqlBase.g4].

Internally, `parse` first prints out the following INFO message to the logs:

```
INFO SparkSqlParser: Parsing command: [command]
```

TIP: Enable `INFO` logging level for the custom `AbstractSqlParser`, i.e. link:spark-sql-SparkSqlParser.adoc#logging[SparkSqlParser] or link:spark-sql-CatalystSqlParser.adoc#logging[CatalystSqlParser], to see the above INFO message.

`parse` then creates and sets up a `SqlBaseLexer` and `SqlBaseParser` that in turn passes the latter on to the input `toResult` function where the parsing finally happens.

NOTE: `parse` uses `SLL` prediction mode for parsing first before falling back to `LL` mode.

In case of parsing errors, `parse` reports a `ParseException`.
