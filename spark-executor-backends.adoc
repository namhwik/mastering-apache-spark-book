== [[ExecutorBackend]] Executor Backends

`ExecutorBackend` is a pluggable interface used by link:spark-executor.adoc[executors] to send status updates about the link:spark-taskscheduler-tasks.adoc#states[different states of a task] to a scheduler.

.ExecutorBackends work on executors and communicate with driver
image::images/executorbackend.png[align="center"]

CAUTION: FIXME What is "a scheduler" in this context?

The interface comes with one method:

```
def statusUpdate(taskId: Long, state: TaskState, data: ByteBuffer)
```

It is effectively a bridge between the driver and an executor, i.e. there are two endpoints running.

CAUTION: FIXME What is cluster scheduler? Where is ExecutorBackend used?

Status updates include information about tasks, i.e. id, link:spark-taskscheduler-tasks.adoc#states[state], and data (as `ByteBuffer`).

At startup, an executor backend connects to the driver and creates an executor. It then launches and kills tasks. It stops when the driver orders so.

There are the following types of executor backends:

* link:spark-local.adoc#LocalBackend[LocalBackend] (local mode)
* link:spark-executor-backends-CoarseGrainedExecutorBackend.adoc[CoarseGrainedExecutorBackend]
* <<MesosExecutorBackend, MesosExecutorBackend>>

=== [[MesosExecutorBackend]] MesosExecutorBackend

CAUTION: FIXME
